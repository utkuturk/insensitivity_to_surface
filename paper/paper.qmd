---
title: "(In)sensitivity to surface-level heuristics: A case from Turkish verbal attractors"
# subtitle: "Within-experiment statistics in agreement attraction"
author:
  - name: Utku Turk
    email: utkuturk@umd.edu
    affiliations:
        - id: umd
          name: University of Maryland, College Park
          department: Linguistics
          address: Marie Mount Hall
          city: College Park
          state: MD
          postal-code: 20742
    attributes:
        corresponding: true
    # note: This is the first author footnote.
abstract: |
  Linguistic illusion literature has stimulated ongoing debate on what type of information can be used to access memory representations.  Prior work tests whether structural, semantic, or discourse cues guide subject-verb dependencies; it remains unclear whether native speakers rely on phonological information as a retrieval cues for memory access during dependency resolution, such as person agreement.  Traditionally, accidental phonological resemblance to having a plural ending as in /s/ sound in *course* was found to not induce erroneous plural agreement, meanwhile, phonological resemblance that correlates with controllerhood amplifies attraction given an already present plural morpheme.  In apparent contradiction to this generalization, Slioussar (2018) proposed that memory search for a subject in Russian sentences can be mediated through an accidental phonological resemblance.  Given the theoretical importance of this proposal and the lack of comparable effects in other languages, we test whether phonological overlap can elicit erroneous agreement in Turkish, where the plural morpheme -lAr surfaces on both nouns and verbs. Turkish provides a critical test: both verbal elements and nominal elements can surface as subjects, but only nominal plural -lAr controls verbal agreement. Two speeded acceptability studies show no attraction from plural-marked verbs (Exp. 1 N = 80; Exp. 2 N = 95) but robust attraction from genitive plural nouns. We report a first-of-its-kind dissociation under minimal manipulation: verbal attractors that can be subjects yet cannot control agreement do not induce attraction, whereas genitive plural nouns that can be subjects and control in other environments do. To our knowledge this pattern has not been shown in any other language, and it constrains cue-based retrieval by tying attraction to abstract controller features rather than surface phonology. 
keywords:
  - form-sensitivity
  - memory
  - agreement attraction
  - linguistic illusions
  - sentence processing
date: last-modified
bibliography: bibliography.bib
format:
  elsevier-pdf:
    pdf-engine: xelatex
    include-in-header:
      - preamble.tex
    keep-tex: true

    # latex-clean: false
    # latex-min-runs: 3
    journal:
      name: Cognition
    #   formatting: preprint
      model: 3p # Don't set a model with preprint
      cite-style: authoryear
  html:
    embed-resources: true
    toc: true
filters:
  - wordcount
execute:
  echo: false
  message: false
  warning: false
---


```{r}
#| label: setup

set.seed(01110011)
library(tidyverse)
library(brms)
library(data.table)
library(gdata)
library(magrittr)
library(DescTools)
select <- dplyr::select
library(lingglosses)
```


```{r}
#| label: functions

read_experimental_data <- function(fname, subj_offset = 0, item_offset = 0, verbose = F) {
    data <- read.csv(fname,
        header = F,
        comment.char = "#",
        encoding = "UTF-8",
        col.names = paste0("V", seq_len(11)),
        fill = TRUE,
        stringsAsFactors = FALSE
    )
    colnames(data) <- c("Time", "MD5", "ControllerType", "SentenceNoInStimFile", "Element", "exp_condition", "item", "Sentence", "Question", "Answer", "RT")

    subject_id <- with(data, {
        as.integer(as.factor(paste(Time, MD5)))
    })
    data$item[data$exp_condition == "intro" | data$exp_condition == "practice"] <- 0
    data$item_num <- as.integer(data$item)
    data$subject <- sprintf("S[%d]", subject_id + subj_offset)
    data$item <- sprintf("I[%d]", data$item_num + item_offset)

    df_forms <- data %>%
        subset(ControllerType != "DashedAcceptabilityJudgment") %>%
        gdata::drop.levels()
    data %<>% subset(ControllerType == "DashedAcceptabilityJudgment")

    age <- df_forms %>%
        dplyr::filter(Sentence == "age") %>%
        dplyr::select(subject, age = Question)
    natturk <- df_forms %>%
        dplyr::filter(Sentence == "natturk") %>%
        dplyr::select(subject, natturk = Question) %T>% {
            .$natturk %<>% recode(male = "nat_turk", female = "nat_non_turk")
        }
    forms <- dplyr::left_join(age, natturk, by = "subject")

    stopifnot(nrow(data) %% 2 == 0)
    rows_stim <- data[c(T, F), ]
    rows_resp <- data[c(F, T), ]
    stopifnot(all(is.na(rows_stim$RT)))

    data <- rows_resp %>%
        left_join(forms) %>%
        dplyr::select(-MD5, -Time, -ControllerType, -Sentence, -Element) %>%
        dplyr::rename(ResponseCorrect = Answer, Response = Question) %>%
        dplyr::select(-ResponseCorrect)
    data %<>% group_by(subject) %>% mutate(trial_no = seq(subject))
    data %<>% mutate(late_response = (Response == "NULL"), Response = ifelse(late_response, NA, as.character(Response)))

    responses <- c(yes = "İYİ (P'ye basınız)", no = "KÖTÜ (Q'ya basınız)")
    data$Response %<>% as.character() %>% enc2native()
    stopifnot(all(data$Response %in% responses | is.na(data$Response)))

    data$response_yes <- ifelse(grepl("P'ye", data$Response), T,
        ifelse(grepl("Q'ya", data$Response), F, NA)
    )
    if (verbose) {
        print(with(data, table(Response, response_yes)))
    }
    data %<>% dplyr::select(-Response)
    data
}


exclude_bad_subjects <- function(data_to_clean, accuracy_threshold = 0.25, rt_below = 200, rt_upper = 4999, verbose = F) {
    avg_by_subj <- data_to_clean %>%
        group_by(
            subject, experiment, condition,
            grammatical, verb_num, attractor_num
        ) %>%
        summarize(
            avRT = mean(RT),
            p_yes = mean(response_yes, na.rm = T),
            N = sum(!is.na(response_yes))
        )

    avg_by_subj_wide <- avg_by_subj %>%
        mutate(expcond = paste(experiment, condition, sep = "_")) %>%
        ungroup() %>%
        dplyr::select(
            -experiment, -condition, -avRT, -N,
            -grammatical, -verb_num, -attractor_num
        ) %>%
        tidyr::spread(expcond, p_yes) %>%
        mutate(delta_dc = AgrAttr_d - AgrAttr_c)

    bad_subjects <- subset(avg_by_subj_wide, delta_dc <= accuracy_threshold) %>% .$subject
    data_clean <- data_to_clean %>% subset(!subject %in% bad_subjects)

    data_clean %<>% filter(RT < rt_upper & rt_below < RT)
    if ("natturk" %in% colnames(data_clean)) {
        data_clean %<>% subset(natturk == "nat_turk")
    }

    if (verbose) {
        print(with(data_clean, table(exp_condition, response_yes)))
        print(sprintf("number of bad subjects: %f", length(bad_subjects)))
    }

    data_clean
}

no_null_no_practice <- function(data_to_clean) {
    data_to_clean %<>% subset(exp_condition != "practice") %>% subset(!is.na(response_yes))
}

asi <- function(x) {
    as.integer(x)
}
asf <- function(x) {
    as.factor(x)
}
asc <- function(x) {
    as.character(x)
}

get_value <- function(df, col, ...) {
    vals <- df %>%
        filter(...) %>%
        pull({{ col }})
    if (is.numeric(vals)) {
        vals <- round(vals, 2)
    } else {
        vals <- as.character(vals)
    }

    vals
}

exclude_bad_subjects_8 <- function(data_to_clean, accuracy_threshold = 0.25, rt_below = 200, rt_upper = 4999, verbose = F) {
    avg_by_subj <- data_to_clean %>%
        group_by(
            subject, experiment, condition,
            grammatical, verb_num, attractor_num, att_type
        ) %>%
        summarize(
            avRT = mean(RT),
            p_yes = mean(response_yes, na.rm = T),
            N = sum(!is.na(response_yes))
        )

    avg_by_subj_wide <- avg_by_subj %>%
        mutate(expcond = paste(experiment, condition, sep = "_")) %>%
        ungroup() %>%
        dplyr::select(
            -experiment, -condition, -avRT, -N,
            -grammatical, -verb_num, -attractor_num, -att_type
        ) %>%
        tidyr::spread(expcond, p_yes) %>%
        mutate(delta_gen_dc = AgrAttr_gen_d - AgrAttr_gen_c, delta_rc_dc = AgrAttr_rc_d - AgrAttr_rc_c)

    bad_subjects_gen <- subset(avg_by_subj_wide, delta_gen_dc <= 0.25) %>% .$subject
    bad_subjects_rc <- subset(avg_by_subj_wide, delta_rc_dc <= 0.25) %>% .$subject
    data_clean <- data_to_clean %>% subset(!subject %in% bad_subjects_gen | !subject %in% bad_subjects_rc)

    data_clean %<>% filter(RT < rt_upper & rt_below < RT)
    if ("natturk" %in% colnames(data_clean)) {
        data_clean %<>% subset(natturk == "nat_turk")
    }
    if (verbose) {
        print(with(data_clean, table(exp_condition, response_yes)))
        print(sprintf("number of bad subjects: %f", length(bad_subjects_gen) + length(bad_subjects_rc)))
    }

    data_clean
}

```


# Introduction

Human sentence processing draws on abstract grammatical features and on heuristics that exploit surface regularities, such as plausibility [@SpeerClifton1998], frequency [@LauEtAl2007], and task-specific factors [@LauraMalsbug24; @ArehalliWittenberg2021; @HammerlyEtAl2019; @LogacevVasishth2016].  We focus on one such heuristic, surface-form overlap, where phonological similarity between the sentence constituents modulates performance [@AchesonMacDonald2011;@KushEtAl2015;@CopelandRadvansky2001; @RastleDavis2008].  Prior work shows reliable slowdowns and comprehension accuracy costs under surface-form overlap, but it is unresolved whether this heuristic penetrates dependency resolution itself, including subject-verb agreement, pronoun resolution, or the licensing of negative polarity items, beyond general effects on reading ease and memory.  The few studies that bear directly on subject-verb agreement exhibit contradictory findings [@BockEberhard1993;@Slioussar2018]. 

A central question for understanding human cognition is what information is encoded and later available to memory during comprehension, and how faithful these encodings are to the input.  A general cue-based retrieval approaches hold that constituents are stored with detailed abstract features and later accessed by matching retrieval cues; it remains open whether phonological codes persist to serve as such cues during dependency building [@LV05].  On the other hand, Good-Enough and noisy accounts allow that detailed analyses are not always maintained when heuristics suffice, raising the possibility that surface regularities affect judgments [@FerreiraEtAl2002].  Clarifying whether surface-form overlap modulates dependency resolution therefore identifies what human cognition counts as diagnostic information for retrieving dependency controllers and how faithful the stored representations are. 

Agreement provides a precise diagnostic because its computations are known to be sensitive to feature overlap. Classic findings in the computation of agreement show that people make systematic errors in establishing a number agreement relation between a verb and its agreement controller, when another NP with a different number (the attractor) interferes. As a result, speakers may produce sentences like (\ref{og}) or misclassify them as acceptable [@BockMiller:1991; @PearlmutterGarnseyBock:1999]. 


```{=latex}
\begin{exe}
\ex[*]{\label{og} The player on the courts are tired from a long-game.}
\end{exe}
```

Despite much research on what quantitatively modulates agreement errors, the role of phonology remains unclear.  Pseudoplurals attractors such as *course* do not increase agreement errors in production, arguing against a purely phonological route [@BockEberhard1993].  Overlaps that align with abstract features or subject-likeness do increase errors, as in case syncretism in German production [@HartsuikerEtAl2003], genitive subject-likeness in Turkish comprehension [@LagoEtAl2019], and structural resemblance in Romanian comprehension [@BleotuDillon2024].  These effects arise when the attractor bears the relevant plural marking and shares morphological features with a possible subject, not when they are singular but phonologically similar to a plural subject, supporting accounts that downplay surface-form similarity.  By contrast, Russian results have been interpreted as evidence that phonological overlap between a singular genitive attractor and a plural nominative form affects agreement judgments, reading, and production [@Slioussar2018].

An alternative interpretation notes that genitive-marked nouns in Russian can participate in other agreement relations, making them plausible agreement controllers in some configurations. This raises the possibility that the observed effects reflect a version of subject-likeness rather than phonology per se. Together, these considerations motivate a targeted test that dissociates the possibility of controllerhood from surface-form overlap.

To this end, we utilize the surface-form overlap between the verbal and nominal morphological reflexes of agreement in Turkish, a language that shows attraction when attractors carry controller-relevant features [@TurkLogacev2024; @Ulusoy2023; @Turk2022; @LagoEtAl2019]. Unlike previously tested languages, Turkish uses the same surface suffix, -lAr, for plural marking on nouns and for plural agreement on finite verbs. Typologically, Turkish is agglutinative with a near one-to-one mapping between grammatical meanings and affixes, in contrast to English, a more analytic language where pure phonological overlap has not yielded attraction, and to Russian, a fusional language where overlap effects have been reported. Crucially, strings bearing verbal -lAr can occur in subject position, yet they never control finite clause agreement; only nominal plurals do. These properties allow a direct test of whether form overlap alone modulates agreement errors, or whether modulation requires an element that can in principle serve as an agreement controller. 

We report two high-powered speeded acceptability experiments in Turkish. Experiment 1 manipulates the number on an embedded verb that appears near the matrix clause, comparing embedded plural -lAr to embedded singular. Experiment 2 retains this manipulation and adds items with nominal plural attractors drawn from prior Turkish work, creating a within-session benchmark for canonical attraction. Across both experiments, embedded verbal -lAr did not increase acceptance of plural matrix agreement. Nominal plural attractors produced the expected attraction. These results indicate that surface-form overlap alone does not function as a retrieval cue for agreement in Turkish. Dependency resolution appears to rely on abstract features and structural relations, with phonology influencing processing primarily outside of retrieval.


## Background

One domain in which these influences are observed is the research on agreement attraction as .  This effect have been robustly attested in many languages with various methodologies [to name a few].  @BockEberhard1993 tested whether attractors that only sound plural, pseudoplurals such as *course* \ref{pseudo}, increase agreement errors compared to true plural nouns (\ref{true-pl}).  They reasoned that if participants rely on phonological cues rather than abstract features, words ending with plural-like sounds (/s/ or /z/) should behave like true plurals. Participants completed sentence preambles such as (\ref{ex:bockeberhard93}), where the head noun (*player*) was singular but the attractor varied in form. They found that pseudoplural attractors did not increase plural agreement rates.


```{=latex}
\begin{exe}
\ex \label{ex:bockeberhard93}
\begin{xlist}
    \ex \label{pseudo} {Pseudoplural Attractor} \\ The {player} on the {course} \ldots{}
    \ex \label{true-sg} {Singular Attractor} \\ The {player} on the {court} \ldots{}
    \ex \label{true-pl} {Plural Attractor} \\ The {player} on the {courts} \ldots{}
\end{xlist}
\end{exe}
```


Even though modulation from a pure phonological similarity was not found, several experiments have manipulated morphological case similarity between controllers and attractors, reasoning that syncretism or surface ambiguity could enhance competition during retrieval or interfere in production [PAPERS].  For example, @HartsuikerEtAl2003 used the overlap between accusative and nominative forms of feminine determiners in German and compared these ambiguous forms to distinctively marked dative forms.  Participants produced more agreement errors when the preambles contained two noun phrases whose determiners were not distinctively marked, as in (\ref{ger-amb}), compared to cases where the attractor could be distinguished by form alone, as in (\ref{ger-dist}).  Crucially, this additive effect was limited to feminine nouns, the only gender showing nominative–accusative syncretism in plural forms while other nouns showed the base effect of plural.

```{=latex}
\begin{exe}
\ex \label{ger}
\begin{xlist}
\ex \label{ger-amb}
\gll Die Stellungnahme gegen die Demonstration-en\\
the.F.NOM.SG position against the.F.ACC.PL demonstration-PL\\
\glt `The position against the demonstrations'
\ex \label{ger-dist}
\gll Die Stellungnahme zu den Demonstration-en\\
the.F.NOM.SG position on the.F.DAT.PL demonstration-PL\\
\glt `The position on the demonstrations'
\end{xlist}
\end{exe}
```

Similar effects of surface similarity are also found in comprehension studies. @Slioussar2018, for example, showed that phonological overlap affects the reading pattern and accuracy of participants in Russian agreement. A group of accusative marked nouns in Russian surfaces ambiguously with their nominative counterparts when they are plural (\ref{RusAccSg}-\ref{RusAccPl}).  Meanwhile, it is possible to assign a different case to the attractors using a different preposition as in (\ref{RusGenSg}-\ref{RusGenPl}). Crucially, in her experiment the genitive marked plural nouns were not ambiguous with their nominative counterparts. @Slioussar2018 showed that participants not only exhibited faster reading times at the verb in (\ref{RusAccPl}) compared to (\ref{RusAccSg}), but also judged sentences with a plural attractor as grammatical more often.  These effects of plural attractor were only present in cases with ambiguous case marking.


```{=latex}
\begin{exe}
\ex
\begin{xlist}
\ex \label{RusAccSg}
\gll ssylka na sajt byli dany.\\
link[NOM.SG] to {website[ACC.SG($\neq$NOM.PL)]} were given\\
\ex \label{RusAccPl}
\gll ssylka na sayty byli dany.\\
link[NOM.SG] to {website[ACC.PL($=$NOM.PL)]} were given\\
\glt `The link to the website(s) were given.'
\ex \label{RusGenSg}
\gll material dlja kry\c{s}i byli brakovannymi.\\
material[NOM.SG] for {roof[GEN.SG($=$NOM.PL)]} were defective\\
\ex \label{RusGenPl}
\gll material dlja kry\c{s} byli brakovannymi.\\
material[NOM.SG] for {roof[GEN.PL($\neq$NOM.PL)]} were defective\\
\glt `The material for the roof(s) were defective.'
\end{xlist}
\end{exe}
```

However, a more intriguing aspect of the study by @Slioussar2018 is her results with respective to attractors marked with genitive singular.  Another interesting characterics of Russian is such that a subset of *singular* genitive nouns share the same form with their plural nominal counterpart.  In addition to plural nouns not increasing grammatical judgments to ungrammatical sentences and not creating a reading advantage, the verbs of singular attractors were read faster and resulted in more 'yes' responses to grammaticality judgments.  In this aspect, the findings of @Slioussar2018 differs from previous syncretism findings and targets the initial question raised by @BockEberhard1993: whether the pure phonological similarity, without any contribution from an abstract plural feature, can drive the agreement attraction effects.

@Slioussar2018 assumed cue-based retrieval model in which attraction effects originates from erroneous retrievals of an agreement controller.  Under this approach, phrases are encoded in a content-addressable memory as bundles of features called *chunks* which include information like, number, gender, morphophonological case, and syntactic information [@SmithVasishth2020;@LV05].  Participants predict the number of the verb based on the noun phrases they process while reading the previous noun phrases.  In grammatical sentences with singular verb agreement, the number prediction and the verb number match, which causes no processing difficulty.  In contrast, when participants fail to find the predicted number morphology on the verb, a memory-retrieval process is initiated.  This process activates the search for a chunk matching relevant cues for agreement controller.  @Slioussar2018 argued that the search for a controller can be mediated through possible forms of nouns with relevant features like, \textsc{nom} case, \textsc{pl} number, as well as structural cues.

In ungrammatical sentences like (\ref{RusAccPl}), while neither of the available noun phrases fully matches this specification in ungrammatical agreement attraction sentences, each of the NPs headed by *link* and *websites* matches a subset of cues.  Importantly, in (\ref{RusGenSg}) as well, a partial match is also possible. Even though the NP headed by *roof* is not plural, due to phonological overlap, @Slioussar2018 argues, a subset of features relevant for agreement, i.e. +NOM and +PL, is erroneously activated.  While this partial match scenarios mostly results in participants finding the sentence ungrammatical, they may occasionally retrieve the attractors, *websites* or *roof*, as controllers on some trials.

An alternative account that does not depend on activation of relevant features by phonology would depend on encoding of distributional facts as statistical heuristics.  In such an account, instead of relying on activation of features through a phonological route, participants would probabilistically associate certain strings, such as genitive marked NP or overt D head, with being an agreement controller.  Indeed, similar explanations for syncretism or subject-likeness phenomenon has been reported.  For example, @LagoEtAl2019 argued that participants can retrieve a noun as the controller if the noun is marked with a case marking that may sometimes control agreement in a language even if that is not the case for the specific sentence.  They used Turkish genitive case, which can control the agreement in embedded sentences but not in matrix sentences.  They took the presence of attraction effects in Turkish as an indication that Turkish speakers utilize overt genitive-case's association with subjecthood.  In a sense, phonological, not functional, syncretism between the marking on the nominal modifier and the embedded subject resulted in attraction.  A similar account from Dillon and colleagues was pushed for sensitivity for looking like a controller in languages like Romanian and Hindi [@BhatiaDillon2022; @BleotuDillon2024].  For instance, @BleotuDillon2024 manipulated whether the attractor surfaces with a determiner or in its bare form.  Importantly, they note that only nouns with determiners can control agreement in Romanian. They found that Romanian attractors only induced attraction effects when both attractor and the head surfaced with a determiner.  They took these results to suggest that participants associated presence of a determiner or related feature with the agreement controller, and attraction only surfaces when subject heads and the attractor look alike.  Similarly, @SchlueterEtAl2018 argue that and can cause agreement attraction effects in English even when it does not create a plurality because it is associated with the plural feature statistically.  Such explanations are based on the assumption that the match between a cue and a chunk does not have to be categorical, but it can be influenced by surface level statistical association [@EngelmannEtAl2019].

A similar account can also be proposed for Russian findings.  Genitive marked nouns can be subjects in negative inversion constructions in Russians.  However, when they are subjects, they cannot control the agreement.  In other cases, they can be the controller of number or gender marking on adjectival relative clauses.  Given this possibility of an alternative account, the contention of initial findings of @BockEberhard1993, and the theoretical importance of the empirical generalization, we test whether pure phonological overlap can derive agreement attraction effects in two high-powered speeded acceptability judgment experiments.  To this end we use Turkish, a language where verbal and nominal plural marking share the same surface form, the suffix –lAr.  We use reduced relative clause (RRC) structures, in which the verb with the plural marking alone can appear as the attractor (\ref{rrc-intro}).  Importantly, Turkish –lAr syncretism here is not feature-ambiguous (as in cases of syncretism); it is a form-only overlap that does not share possible argument status with the subject.  Even when the RRC can surface without its head as the subject, they cannot control the agreement (\ref{rrc-subject}).


```{=latex}
\begin{exe}
\ex \label{rrc-intro}
\gll Gör-dük-ler-i çocuk koş-tu-(*lar).\\
go-NMLZ-PL-POSS kid[NOM] run-PST-(*PL)\\
\glt `The kid that (they) saw ran.'
\ex \label{rrc-subject}
\gll Gör-dük-ler-i koş-tu-(*lar).\\
go-NMLZ-PL-POSS run-PST-(*PL)\\
\glt `(The kid) that (they) saw ran.'
\end{exe}
```


In Experiment 1, we tested the form hypothesis directly by comparing ungrammatical sentences with verbal-plural vs. verbal-singular attractors.  Experiment 2 replicated this design but included additional nominal-attractor items from a previous Turkish attraction study [@TurkLogacev2024], allowing us to test whether the distribution of item types and the presence of genuine attraction-inducing elements modulates the outcome.  Across both experiments, we found no evidence that verbal –lAr induces attraction, even when canonical nominal attractors are present in the same session.  This pattern aligns with prior findings in general attraction literature and Turkish agreement attraction, namely surface-form overlap alone does not derive agreement illusions.  Rather, attraction appears to depend on abstract feature overlap between potential controllers and agreement probes, and possibly statistical associations between the strings and their controllers.  In this lights, findings of @Slioussar2018 are best analyzed as a possible increased association between genitive marking and possible subjecthood and being an agreement controller.  By doing so, we hope to clarify how cue-mechanisms are employed and the role of phonological overlap in sentence processing.


<!-- becomes even more surprising given that singular attractors that are homophonous with plurals were able to induce attraction effects.  One way to reconcile these findings is to refer to types of morphological encoding or the functional utility of morphemes in specific languages following @DillonKeshev2024. -->


<!-- However, it is not clear how much phonology plays a role in determining such associations with being a controller in these explanations.  As it stands, their proposals are compatible with the stronger version of the hypothesis which is put forwards by the @Slioussar2018, namely purely phonological similarity is enough to induce attraction effects.      @BleotuDillon2024 acknowledge that their results are compatible with explanations in which the activation of a chunk is statistical distribution within a language and this statistical distribution can be influenced by surface level associations [@EngelmannEtAl2019; @SchlueterEtAl2018].   -->


<!-- Turkish verbal -lAr presents a clear dissociation between form-association with subjecthood and being a controller.  As we previously noted, they can surface as a subject, they do look like a controller, but they cannot control the agreement and they are not possible controllers.  In this aspect, Turkish verbal -lAr is similar to Russian genitive cases.  If verbal -lAr, like Russian genitive case, induce attraction errors, current models of attraction need to be revised to include phonological similarity beyond being a possible controller. -->






<!-- Given the contention of initial findings of @BockEberhard1993 with Russian data and the theoretical importance of the empirical generalization, we tested whether we could find attraction effects with another type morphologically rich language, Turkish.  Turkish, an almost-strict agglutinative language, presents another typological aspects of morphological marking.  English, a predominantly analytic language that uses separate words, such as prepositions, particles, and auxiliary verbs, to express grammatical meaning rather than relying on inflections or affixes attached to words did not show an effect of pure phonological overlap.  Meanwhile, Russian, a fusional language in which a single affixal morpheme can express multiple grammatical meanings, exhibited the effect of phonological overlap.  Turkish represents another group of languages in which there is close to 1-to-1 mapping between gramatical meanings and affixal morphemes. -->





<!-- ## Primer on Attraction Accounts and Phonological Modulation -->

<!-- Agreement errors in sentences like (\ref{og}) have been treated either as a failure of feature reconcilation or a failure of memory encoding.   -->

<!-- The former set of accounts explain these errors as a by-product of how number feature of a phrase is calculated in real-time [@BockMiller:1991; @EberhardEtAl2005; @HammerlyEtAl2019].  For example, @EberhardEtAl2005, in their Marking and Morphing account, argue that speakers and comprehenders does not necessarily create binary singular or plural representation, instead they consider various number related information in a phrase and create a continuous value.  This related information include (i) the inherent conceptual number of the head of phrase, namely collectiveness or distributiveness of a noun, (ii) grammatical number markings on all nouns within a phrase weighted by their syntactic distance, and (iii) idiosyncretic (scissors) or grammatical (books) presence of a plural marking.  The errors probabilistically arise when additional plurality features from different sources contribute to the final number representation of a phrase.  Because this account ties attraction to various sources including the presence of a plural morpheme, it could in principle accommodate effects of surface-form similarity.  However, this surface form similarity effects should be limited to the cases where it can be associated with a plural number marking, and should not arise with pure phonological similarities. -->

<!-- On the other hand, the latter set of accounts claim that the initial representation is not erroneous, but speakers are sometimes unable to correctly retrieve the controller [@WagersEtAl:2009; @Dillon2013a; @RyskinEtAl2021].  For example, @WagersEtAl:2009, in their memory account, assumes a cue-based retrieval model in which the verb cues a search for a memory chunk matching relevant cues for subjecthood and number.  In the ungrammatical attraction sentences as in (\ref{og}), each of chunks for ‘courts’ and ‘player’ matches a subset of relevant cues.  In these partial match scenarios, erroneously retrieval of the attractor may lead comprehenders to judge the sentence grammatical.  In this framework, surface-form overlap affects processing only if it contributes to cue overlap.  For example, plural morphology or phonological endings could influence retrieval if the system treats them as diagnostic of plural number.  Because the model allows cues to be weighted differently depending on their reliability, it trivially accounts for cross-linguistic variability in the role of case marking and other morphosyntactic features. -->

<!-- The two main set of explanations, therefore, make different predictions for the influence of surface similarity.  Feature reconcilation accounts predict form-based attraction if overlapping phonology also results in overlapping morphological representations, whereas cue-based retrieval predicts form effects only when they are encoded as retrieval cues, i.e. relevant for predictions.  -->




# Experiment 1: Testing Form-Driven Processing

```{r}
#| label: exp1-data-prep

exp1 <- read_experimental_data("../data/results.txt", subj_offset = 2000, item_offset = 2000)

exp1 %<>% mutate(exp_condition = case_when(
  exp_condition == "filler" & item_num <= 120 ~ "filler_ung",
  exp_condition == "filler" & item_num >= 121 ~ "filler_g",
  exp_condition == "practice" ~ "practice",
  exp_condition == "condition_b" ~ "condition_b",
  exp_condition == "condition_a" ~ "condition_a",
  exp_condition == "condition_c" ~ "condition_c",
  exp_condition == "condition_d" ~ "condition_d"
))


exp1.conditions <- data.frame(
  exp_condition = c("practice", "condition_a", "condition_b", "condition_c", "condition_d", "filler_ung", "filler_g"),
  experiment =    c("practice", "AgrAttr",     "AgrAttr",     "AgrAttr",     "AgrAttr",     "filler",     "filler"),
  condition =     c("practice", "a",           "b",           "c",           "d",           "filler_ung", "filler_g"),
  grammatical =   c("practice", "ungram",      "gram",        "ungram",      "gram",        "ungram",     "gram"),
  verb_num =      c("practice", "pl",          "sg",          "pl",          "sg",          "sg",         "pl"),
  attractor_num = c("practice", "pl",          "pl",          "sg",          "sg",          'filler',     'filler'),
  match =         c("practice", "mismatch",    "mismatch",    "match",       "match",       'filler',     'filler'),
  stringsAsFactors = T
)

exp1 %<>% left_join(exp1.conditions, by = "exp_condition")

exp1.no.practice <- exp1 %>% subset(exp_condition != "practice")

# accuracy: 0.25
# rt_below: 200
# rt_upper: 4999
exp1.clean <- exclude_bad_subjects(
  exp1,
  accuracy_threshold = 0.25,
  rt_below = 200,
  rt_upper = 4999
)

exp1.clean %<>% no_null_no_practice(.)

stopifnot(exp1.clean %>% subset(is.na(response_yes)) %>% nrow() == 0)

# DIFF DATA =====
exp1.diff <- dplyr::anti_join(exp1, exp1.clean) %>%
  filter(exp_condition != "practice")

exp1.clean$isGram <- ifelse(exp1.clean$grammatical == "ungram", F, T)
exp1.clean$p_acc <- with(exp1.clean, response_yes & isGram)
exp1.clean %<>% mutate(ResponseCorrect = (response_yes == (grammatical == "gram")))

# Merge

exp1.clean %<>% ungroup() %>%
                      dplyr::select(source=experiment,
                                    grammatical,
                                    attractor_num,
                                    match,
                                    age,
                                    # condition,
                                    subject,
                                    trial_no,
                                    item,
                                    response_yes,
                                    RT,
                                    ResponseCorrect)
exp1.clean$experiment <- "Experiment 1"
exp1.clean$grammatical %<>% dplyr::recode(gram="grammatical", ungram="ungrammatical")
exp1.clean$attractor_num %<>% dplyr::recode(pl="plural", sg="singular")
exp1.clean$item %<>% as.factor()
exp1.clean$subject %<>% as.character()

```

```{r}
#| label: exp1-avgs

exp1.avgs <- exp1.clean %>%
  filter(match != "filler") %>%
  group_by(grammatical, attractor_num, match) %>%
  summarise(
    successes = sum(response_yes == 1, na.rm = TRUE),
    N         = sum(!is.na(response_yes)),
    .groups = "drop"
  ) %>%
  mutate(ci_mat = purrr::pmap(
    list(successes, N),
    ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
  )) %>%
  mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
  unnest(ci_mat) %>%
  mutate(
    p_hat = successes / N,
    lwr   = lwr.ci,
    upr   = upr.ci
  ) %>%
  select(grammatical, attractor_num, match, successes, N, p_hat, lwr, upr)

exp1.avgs.filler <- exp1.clean %>%
  filter(match == "filler") %>%
  group_by(grammatical, attractor_num, match) %>%
  summarise(
    successes = sum(response_yes == 1, na.rm = TRUE),
    N         = sum(!is.na(response_yes)),
    .groups = "drop"
  ) %>%
  mutate(ci_mat = purrr::pmap(
    list(successes, N),
    ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
  )) %>%
  mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
  unnest(ci_mat) %>%
  mutate(
    p_hat = successes / N,
    lwr   = lwr.ci,
    upr   = upr.ci
  ) %>%
  select(grammatical, attractor_num, match, successes, N, p_hat, lwr, upr)


```

```{r}
#| label: exp1-text-inputs

# I want accuracy, not the response yes
exp1.avgs.filler %<>%
  mutate(old.lwr = lwr, old.upr = upr) %>%
  mutate(
  p_hat = if_else(grammatical == "ungrammatical", 1 - p_hat, p_hat),
  lwr = if_else(grammatical == "ungrammatical", 1 - old.upr, old.lwr),
  upr = if_else(grammatical == "ungrammatical", 1 - old.lwr, old.upr))  %>%
  select(-old.lwr, -old.upr)


exp1.nsubj <- exp1$subject %>% unique() %>% length()

exp1.nsubj.nontr <- exp1 %>%
  subset(natturk == "nat_non_turk") %>%
  .$subject %>%
  unique() %>%
  length()

exp1.nsubj.threshold <- 2

exp1.deletion <- round(100*((nrow(exp1.no.practice)-nrow(exp1.clean))  / nrow(exp1.no.practice)),2)


exp1.meanage <- mean(asi(exp1.clean$age)) %>% round()
exp1.maxage <- max(asi(exp1.clean$age))
exp1.minage <- min(asi(exp1.clean$age))

# FILLER AVERAGES

exp1.avgs.filler %<>% mutate(text = paste0("M = ", round(p_hat,2), ", CI = [", round(lwr,2) , ",", round(upr,2) ,"]"))

exp1.avgs %<>% mutate(text = paste0("M = ", round(p_hat,2), ", CI = [", round(lwr,2) , ",", round(upr,2) ,"]"))

```


## Participants

We recruited `r exp1.nsubj` undergraduate students to participate in the experiment in exchange for course credit. All participants were native Turkish speakers, with an average age of `r exp1.meanage` (range: `r exp1.minage` – `r exp1.maxage`). The experiment was carried out following the principles of the Declaration of Helsinki and the regulations concerning research ethics at Bogazici University. All participants provided informed consent before their participation and their identities were completely anonymised.

## Materials

We used 40 sets of sentences like (\ref{exp}), in which we manipulated (i) the number of the attractor and (ii) the number agreement on the verb. Both plural markings were marked with the suffix -ler/-lar, while the singular number and singular agreement were marked by its absence.

```{=latex}
\begin{exe}
\ex \label{exp}
\begin{xlist}
\ex[]{\label{ss}
\gll Tut-tuğ-u aşçı mutfak-ta sürekli zıpla-dı.\\
hire-NMLZ-POSS cook[NOM] kitchen-LOC non.stop jump-PST\\
\glt `The cook they hired$_{sg}$ jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{sp}
\gll Tut-tuğ-u aşçı mutfak-ta sürekli zıpla-dı-lar.\\
hire-NMLZ-POSS cook[NOM] kitchen-LOC non.stop jump-PST-PL\\
\glt `The cook they hired$_{sg}$ jumped$_{pl}$ in the kitchen non-stop.'}
\ex[]{\label{ps}
\gll Tut-tuk-lar-ı aşçı mutfak-ta sürekli zıpla-dı.\\
hire-NMLZ-PL-POSS cook[NOM] kitchen-LOC non.stop jump-PST\\
\glt `The cook they hired$_{pl}$ jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{pp}
\gll Tut-tuk-lar-ı aşçı mutfak-ta sürekli zıpla-dı-lar.\\
hire-NMLZ-PL-POSS cook[NOM] kitchen-LOC non.stop jump-PST-PL\\
\glt `The cook they hired$_{pl}$ jumped$_{pl}$ in the kitchen non-stop.'}
\end{xlist}
\end{exe}
```

All sentences were adapted by previous studies in Turkish agreement attraction [@LagoEtAl2019;@TurkLogacev2024]. Sentences started with a complex subject NP like 'tuttukları aşçı' 'the cook they hired,' in which the nominalized relative clause functioned as the attractor, and the head noun were bare. Because the plural marking on nominals is not optional and the head noun was singular, absent of -lar, in all conditions, sentences with plural verb agreement were ungrammatical. To inhibit participants from forming a task-related strategy in which they deemed the sentence ungrammatical upon seeing a plural verb, half of our fillers included plural grammatical verbs, while the other half included singular ungrammatical verbs.

## Procedures

The experiment was run online, using the web-based platform Ibex Farm [@Drummond2013]. Each experimental session took approximately 25 minutes to complete. Participants provided demographic information and gave informed consent to participate in the experiment. They then proceeded to read the instructions and were given nine practice trials before the experiment began.

Each trial began with a blank screen for 600 ms, followed by a word-by-word RSVP presentation of the sentence in the center of the screen, followed by a prompt to indicate their acceptability judgment. Sentences were presented word-by-word in the center of the screen in 30 pt font size, at a rate of 400 ms per word. Participants saw a blank screen for 100 ms between each word, and to see the next item, they needed to press the space key. Participants were asked to press the key P to indicate that a sentence is acceptable and Q to indicate that the sentence is unacceptable. They were instructed to provide judgments as quickly as possible. During the practice, but not during the experiment, a warning message in red font appeared if they did not respond within 5,000 ms.

Participants saw 40 experimental and 40 filler sentences. Experimental sentences were distributed among four different lists according to a Latin-square design. Every participant saw one version of the experiment with a specific list and one item per condition.


## Analysis and Results



```{r}
#| label: exp1-models

options(mc.cores = parallel::detectCores())
theme_set(theme_bw(base_family = "Times"))


exp1.dfModel <- exp1.clean %>% subset(match != "filler")


exp1.dfModel %<>%
    mutate(
        grammatical = factor(grammatical,
            levels = c("grammatical", "ungrammatical"),
            labels = c("Grammatical", "Ungrammatical")
        ),
        attractor_num = factor(attractor_num, # or attractor_num if that’s your column
            levels = c("singular", "plural"),
            labels = c("Singular", "Plural")
        )
    )

# Sum-code ±0.5 and give readable column names
C2 <- contr.sum(2) / 2

Cg <- C2
colnames(Cg) <- "Gram_minus_Ungram" # β > 0 ⇒ Ungram > Gram (in log-odds of YES)
Ca <- C2
colnames(Ca) <- "Plural_minus_Singular" # β > 0 ⇒ Plural > Singular (log-odds of YES)

contrasts(exp1.dfModel$grammatical) <- Cg
contrasts(exp1.dfModel$attractor_num) <- -Ca


make_priors <- function(
    inter_ga_mean = 0.0, inter_ga_sd = 0.10, # Gram × Attr (classic attraction term)
    main_g_mean = 1.0, main_g_sd = 0.50, # Grammaticality main effect (your previous spec)
    main_a_mean = 0.30, main_a_sd = 0.40, # Attractor Number main effect
    intercept_mean = 0.85, intercept_sd = 0.70,
    exp_rate = 1, lkj_eta = 2) {
    c(
        # Intercept
        set_prior(sprintf("normal(%g, %g)", intercept_mean, intercept_sd), class = "Intercept"),

        # Main effects
        set_prior(sprintf("normal(%g, %g)", main_g_mean, main_g_sd),
            class = "b", coef = "grammaticalGram_minus_Ungram"
        ),
        set_prior(sprintf("normal(%g, %g)", main_a_mean, main_a_sd),
            class = "b", coef = "attractor_numPlural_minus_Singular"
        ),
        # Two-way interactions
        set_prior(sprintf("normal(%g, %g)", inter_ga_mean, inter_ga_sd),
            class = "b", coef = "grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular"
        ),
        # Random-effect scales and correlations
        set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
        set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
    )
}

priors_uninformative <- make_priors(
    inter_ga_mean   = 0, inter_ga_sd   = 1,
    main_g_mean     = 0, main_g_sd     = 1,
    main_a_mean     = 0, main_a_sd     = 1,
    intercept_mean  = 0, intercept_sd  = 1,
    exp_rate        = 1,
    lkj_eta         = 2
)


m.exp1 <- brm(
    response_yes ~ grammatical * attractor_num +
        (1 + grammatical * attractor_num | subject) +
        (1 + grammatical * attractor_num | item),
    data = exp1.dfModel,
    family = bernoulli(link = "logit"),
    prior = priors_uninformative,
    sample_prior = "yes", file = "m.exp1",
    save_pars = save_pars(all = TRUE),
    chains = 4, iter = 10000, warmup = 2500, seed = 1
)




# make uninformative priors.
make_priors <- function(inter_mean = 0.4, inter_sd = 0.1,
                        exp_rate = 1, lkj_eta = 2) {
    c(
        set_prior("normal(0.85, 0.7)", class = "Intercept"),
        set_prior("normal(1.0, 0.5)",
            class = "b",
            coef = "grammaticalGram_minus_Ungram"
        ),
        set_prior("normal(0.30, 0.40)",
            class = "b",
            coef = "attractor_numPlural_minus_Singular"
        ),
        set_prior(sprintf("normal(%g, %g)", inter_mean, inter_sd),
            class = "b",
            coef = "grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular"
        ),
        set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
        set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
    )
}


# Default: mean 0.4, sd 0.25 (the “interaction” model)
# exp2.priors_interaction_exp <- make_exp2_priors()

# Near-zero interaction model
# exp2.priors_no_interaction_exp <- make_exp2_priors(inter_mean = 0, inter_sd = 0.10)

# Strong positive interaction (e.g. mean 0.8)
# exp2.priors_strong_interaction <- make_exp2_priors(inter_mean = 0.8, inter_sd = 0.25)

# m.exp1.no.int <- brm(
#     response_yes ~ grammatical * attractor_num +
#         (1 + grammatical * attractor_num | subject) +
#         (1 + grammatical * attractor_num | item),
#     data = exp1.dfModel,
#     family = bernoulli(link = "logit"),
#     prior = make_priors(inter_mean = 0),
#     sample_prior = "yes", file = "m.exp1.int",
#     save_pars = save_pars(all = TRUE),
#     chains = 4, iter = 10000, warmup = 2500, seed = 1
# )


# m.exp1.int <- brm(
#     response_yes ~ grammatical * attractor_num +
#         (1 + grammatical * attractor_num | subject) +
#         (1 + grammatical * attractor_num | item),
#     data = exp1.dfModel,
#     family = bernoulli(link = "logit"),
#     prior = make_priors(),
#     sample_prior = "yes", file = "m.exp1.no.int",
#     save_pars = save_pars(all = TRUE),
#     chains = 4, iter = 10000, warmup = 2500, seed = 1
# )


```



```{r}
#| label: model-output


library(posterior)
library(glue)

# --- helpers ---
coef_names <- list(
    gram  = "b_grammaticalGram_minus_Ungram",
    attr  = "b_attractor_numPlural_minus_Singular",
    inter = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular"
)
summ_brms <- function(fit, par) {
    s <- posterior_summary(fit, pars = par)[1, ]
    c(est = unname(s["Estimate"]), l95 = unname(s["Q2.5"]), u95 = unname(s["Q97.5"]))
}
fmt <- function(x, d = 2) sprintf(paste0("%.", d, "f"), x)
trip <- function(v, d = 2) glue("{fmt(v['est'], d)} [{fmt(v['l95'], d)}, {fmt(v['u95'], d)}]")

post_int <- list(
    gram  = summ_brms(m.exp1, coef_names$gram),
    attr  = summ_brms(m.exp1, coef_names$attr),
    inter = summ_brms(m.exp1, coef_names$inter)
)
txt <- list(
    gram  = trip(post_int$gram),
    attr  = trip(post_int$attr),
    inter = trip(post_int$inter)
)

p_gt0 <- function(fit, par) {
    sanitize_b <- function(par) paste0("", sub("b_", "", par))

    h <- hypothesis(fit, paste0(sanitize_b(par), " > 0"))
    as.numeric(h$hypothesis$Post.Prob)
}

txt_p <- list(
    gram  = fmt(p_gt0(m.exp1, coef_names$gram), 2),
    attr  = fmt(p_gt0(m.exp1, coef_names$attr), 2),
    inter = fmt(p_gt0(m.exp1, coef_names$inter), 2)
)

```


```{r}
#| label: nested-models


grammaticals <- exp1.dfModel %>% filter(grammatical == "Grammatical")

ungrammaticals <- exp1.dfModel %>% filter(grammatical == "Ungrammatical")

make_priors_g <- function(inter_mean = 0.4, inter_sd = 0.1,
                        exp_rate = 1, lkj_eta = 2) {
    c(
        set_prior("normal(0.85, 0.7)", class = "Intercept"),
        set_prior("normal(0.30, 0.40)",
            class = "b",
            coef = "attractor_numPlural_minus_Singular"
        ),
        set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
        set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
    )
}

m.exp1.g <- brm(
    response_yes ~ attractor_num +
        (1 + attractor_num | subject) +
        (1 + attractor_num | item),
    data = grammaticals,
    family = bernoulli(link = "logit"),
    prior = make_priors_g(),
    sample_prior = "yes", file = "m.exp1.g",
    save_pars = save_pars(all = TRUE),
    chains = 4, iter = 4000, warmup = 2000, seed = 1
)


m.exp1.u <- brm(
    response_yes ~ attractor_num +
        (1 + attractor_num | subject) +
        (1 + attractor_num | item),
    data = ungrammaticals,
    family = bernoulli(link = "logit"),
    prior = make_priors_g(),
    sample_prior = "yes", file = "m.exp1.u",
    save_pars = save_pars(all = TRUE),
    chains = 4, iter = 4000, warmup = 2000, seed = 1
)

post_int_g <- list(
    attr_g  = summ_brms(m.exp1.g, coef_names$attr),
    attr_u  = summ_brms(m.exp1.u, coef_names$attr)
)

txt_g <- list(
    attr_g = trip(post_int_g$attr_g),
    attr_u = trip(post_int_g$attr_u)
)

txt_g_p <- list(
    attr_g = fmt(p_gt0(m.exp1.g, coef_names$attr), 2),
    attr_u = fmt(p_gt0(m.exp1.u, coef_names$attr), 2)
)



```

Participants showed high accuracy in both grammatical (`r get_value(exp1.avgs.filler, text, grammatical == "grammatical")`) and ungrammatical filler sentences (`r get_value(exp1.avgs.filler, text, grammatical == "ungrammatical")`), indicating that they understood the task and performed it reliably.

Figure 1 presents the overall means and credible intervals for 'yes' responses across experimental conditions. As shown, ungrammatical sentences with plural attractors were rated as acceptable as their counterparts with singular attractors (M = `r get_value(exp1.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "singular")` and `r get_value(exp1.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "plural")`, CI = [`r get_value(exp1.avgs, lwr, grammatical == "ungrammatical", attractor_num == "singular")`, `r get_value(exp1.avgs, upr, grammatical == "ungrammatical", attractor_num == "singular")`] and [`r get_value(exp1.avgs, lwr, grammatical == "ungrammatical", attractor_num == "plural")`, `r get_value(exp1.avgs, upr, grammatical == "ungrammatical", attractor_num == "plural")`] for singular and plural attractors, respectively).

On the other hand, accuracy in grammatical conditions was modulated by the number of the attractor in an unexpected way. Participants rated grammatical sentences with singular attractors as grammatical less often (`r get_value(exp1.avgs, text, grammatical == "grammatical", attractor_num == "singular")`) compared to their counterpars with plural attractors (`r get_value(exp1.avgs, text, grammatical == "grammatical", attractor_num == "plural")`).


```{r}
#| label: exp1-condition-means
#| fig-cap: "Mean proportion of 'acceptable' responses by grammaticality and attractor number. Error bars show 95% Clopper–Pearson confidence intervals. "
#| fig-width: 6
#| fig-height: 3.5

exp1.gram.label <- c(
    grammatical = "Grammatical\n(Singular Verb)",
    ungrammatical = "Ungrammatical\n(Plural Verb)"
)

# responses

exp1.avgs %>%
    ggplot(aes(grammatical, p_hat,
        linetype = attractor_num,
        group = attractor_num
    )) +
    geom_point() +
    geom_line() +
    geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.1) +
    theme(strip.background = element_rect(fill = "white")) +
    xlab("Grammaticality") +
    ylab("Percentage 'acceptable'") +
    scale_y_continuous(labels = scales::percent) +
    scale_linetype_discrete(
        name = "Attractor Number",
        labels = c("Plural", "Singular")
    ) +
    scale_x_discrete(labels = exp1.gram.label) +
    theme_minimal(base_family = "Times") +
    theme(legend.position = "bottom")

```

These descriptive trends were confirmed by our Bayesian mixed-effects models implemented in brms,  assuming a Bernoulli logit link. The model was fitted to the binary *yes/no* responses and included fixed effects for Grammaticality and Attractor Number and their interaction, and random intercepts and slopes for both subjects and items.

Posterior estimates are summarized in Figure 2. The model revealed a positive effect of grammaticality ($\beta$ = `r txt$gram`, P($\beta$ > `r txt_p$gram`)), but no reliable main effect of attractor number ($\beta$ = `r txt$attr`, P($\beta$ > `r txt_p$attr`)). On the other hand, there was a small but positive interaction ($\beta$ = `r txt$inter`, P($\beta$ > `r txt_p$inter`)). To clarify the effects' presence in grammaticals only, we fitted two more models that is fitted to the subset of the data. While the model fitted to grammatical conditions only showed an effect of attractor number ($\beta$ = `r txt_g$attr_g`, P($\beta$ > `r txt_g_p$attr_g`)), the model fitted to ungrammatical conditions did not provide evidence for the effect of number manipulation ($\beta$ = `r txt_g$attr_u`, P($\beta$ > `r txt_g_p$attr_g`)). These results suggest that the presence of a plural attractor did not increase the acceptability of ungrammatical sentences, nor was this relationship modulated by grammaticality.


```{r}
#| label: exp1-fixed-effects
#| fig-cap: "Posterior means and 95% credible intervals for fixed effects in the two Bayesian models. The x-axis shows the posterior mean (log-odds scale). The blue intervals correspond to the model in which a positive interaction was assumed, and the orange intervals to the model in which it was not. "
#| fig-width: 6
#| fig-height: 2

fixef_whiskers <- function(fit, label) {
    posterior_summary(fit, pars = "^b_") %>%
        as_tibble(rownames = "term") %>%
        filter(term != "b_Intercept") %>%
        transmute(
            term,
            est = Estimate,
            l95 = Q2.5,
            u95 = Q97.5,
            model = label
        )
}

lab_no_int <- "Not assumed\nN(0,0.25)"
lab_int <- "Assumed\nN(0.4,0.25)"

df_plot <- bind_rows(
    fixef_whiskers(m.exp1, "Uninformative")
) %>%
    mutate(
        term_clean = case_when(
            term == "b_grammaticalGram_minus_Ungram" ~ "Grammaticality",
            term == "b_attractor_numPlural_minus_Singular" ~ "Attractor",
            term == "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular" ~ "Interaction",
            TRUE ~ term
        ),
        term_clean = factor(term_clean,
            levels = rev(c("Grammaticality", "Attractor", "Interaction"))
        )
    )

ggplot(df_plot, aes(x = est, y = term_clean)) +
    geom_vline(xintercept = 0, linetype = 3) +
    geom_errorbarh(aes(xmin = l95, xmax = u95),
        position = position_dodge(width = 0.5), height = 0.2
    ) +
    geom_point(position = position_dodge(width = 0.5), size = 2.4) +
    labs(
        x = "Posterior (log-odds)",
        y = NULL,
        color = "Interaction",
    ) +
    theme_minimal(base_size = 10, base_family = "Times") +
    theme(panel.grid.minor = element_blank())

```

## Discussion

Experiment 1 tested whether phonological overlap between nominal and verbal plural morphemes in Turkish induces agreement attraction. The results provided no evidence for attraction driven by surface-form similarity. Ungrammatical sentences with plural-marked verbs were not judged more acceptable when the relative clause verb contained a plural morpheme. Instead, participants reliably rejected such sentences regardless of attractor number. This indicates that the verbal plural marker -lAr does not create the same type of interference observed with nominal plural attractors in previous studies.

Unexpectedly, grammatical sentences with singular attractors were judged less acceptable than those with plural attractors. This effect is unlikely to reflect agreement attraction, since it arises in the opposite direction. One possibility is that it results from an interaction between plausibility and referential availability. The plural morpheme can license a more general interpretation by allowing an arbitrary or unspecific reference, whereas the singular reduced relative clause more strongly invites a specific referent, which may be less accessible in the context of the task. In other words, plural morphology may facilitate an *arbitrary PRO* interpretation of the embedded clause, in which the understood subject of the relative clause is not controlled by any overt antecedent and has a generic or impersonal reference. A similar effect can be seen in English sentences like 'Just to sit there should be forbidden.' Here, the subject of the infinitival clause has arbitrary reference. We do not pursue this explanation further, as it falls outside the scope of the present paper.

One possible reason for the absence of attraction may lie in the within-experiment statistics. Previous work has shown that participants' global expectations about the frequency of grammatical and ungrammatical sentences can alter attraction patterns. @HammerlyEtAl2019 and @Turk2022 demonstrated that reducing the proportion of grammatical trials led to attraction effects even in otherwise grammatical sentences. Similarly, @ArehalliWittenberg2021 reported that filler distribution affects error correction rates. It is possible that the current experiment’s distribution discouraged attraction: if participants rarely encountered conditions that supported attraction, they may have maintained a strong bias against plural-marked verbs, reinforcing this bias throughout the session.

To test this possibility, Experiment 2 introduced additional conditions that have previously been shown to elicit attraction in Turkish \citep{TurkLogacev2024, LagoEtAl2019}. This allowed us to assess whether the inclusion of genuine nominal attractors modulates the likelihood of errors and whether participants adapt to the statistical environment of the task.

# Experiment 2: Testing Within-Experiment Statistical Sensitivity



```{r}
#| label: exp2-data-prep

exp2 <- read_experimental_data("../data/results_8cond.txt", subj_offset = 2500, item_offset = 2500)

exp2 %<>% mutate(exp_condition = case_when(
    exp_condition == "filler" & item_num <= 120 ~ "filler_ung",
    exp_condition == "filler" & item_num >= 121 ~ "filler_g",
    exp_condition == "practice" ~ "practice",
    exp_condition == "condition_gen_b" ~ "condition_gen_b",
    exp_condition == "condition_gen_a" ~ "condition_gen_a",
    exp_condition == "condition_gen_c" ~ "condition_gen_c",
    exp_condition == "condition_gen_d" ~ "condition_gen_d",
    exp_condition == "condition_rc_b" ~ "condition_rc_b",
    exp_condition == "condition_rc_a" ~ "condition_rc_a",
    exp_condition == "condition_rc_c" ~ "condition_rc_c",
    exp_condition == "condition_rc_d" ~ "condition_rc_d"
))


exp2.conditions <- data.frame(
    exp_condition = c("practice", "condition_gen_a", "condition_gen_b", "condition_gen_c", "condition_gen_d", "condition_rc_a", "condition_rc_b", "condition_rc_c", "condition_rc_d", "filler_ung", "filler_g"),
    experiment = c("practice", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "filler", "filler"),
    condition = c("practice", "gen_a", "gen_b", "gen_c", "gen_d", "rc_a", "rc_b", "rc_c", "rc_d", "filler_ung", "filler_g"),
    grammatical = c("practice", "ungram", "gram", "ungram", "gram", "ungram", "gram", "ungram", "gram", "ungram", "gram"),
    verb_num = c("practice", "pl", "sg", "pl", "sg", "pl", "sg", "pl", "sg", "sg", "pl"),
    attractor_num = c("practice", "pl", "pl", "sg", "sg", "pl", "pl", "sg", "sg", "filler", "filler"),
    match = c("practice", "mismatch", "mismatch", "match", "match", "mismatch", "mismatch", "match", "match", "filler", "filler"),
    att_type = c("practice", rep("gen", 4), rep("rc", 4), "filler", "filler"),
    stringsAsFactors = T
)

exp2 %<>% left_join(exp2.conditions, by = "exp_condition")

exp2.no.practice <- exp2 %>% subset(exp_condition != "practice")

# accuracy: 0.25
# rt_below: 200
# rt_upper: 4999
exp2.clean <- exclude_bad_subjects_8(
    exp2,
    accuracy_threshold = 0.25,
    rt_below = 200,
    rt_upper = 4999
)

exp2.clean %<>% no_null_no_practice(.)

stopifnot(exp2.clean %>% subset(is.na(response_yes)) %>% nrow() == 0)

# DIFF DATA =====
exp2.diff <- dplyr::anti_join(exp2, exp2.clean) %>%
    filter(exp_condition != "practice")

exp2.clean$isGram <- ifelse(exp2.clean$grammatical == "ungram", F, T)
exp2.clean$p_acc <- with(exp2.clean, response_yes & isGram)
exp2.clean %<>% mutate(ResponseCorrect = (response_yes == (grammatical == "gram")))

# Merge

exp2.clean %<>% ungroup() %>%
    dplyr::select(
        source = experiment,
        grammatical,
        attractor_num,
        att_type,
        match,
        age,
        # condition,
        subject,
        trial_no,
        item,
        response_yes,
        RT,
        ResponseCorrect
    )
exp2.clean$experiment <- "Experiment 1"
exp2.clean$grammatical %<>% dplyr::recode(gram = "grammatical", ungram = "ungrammatical")
exp2.clean$attractor_num %<>% dplyr::recode(pl = "plural", sg = "singular")
exp2.clean$att_type %<>% dplyr::recode(gen = "gen", rc = "rc")
exp2.clean$item %<>% as.factor()
exp2.clean$subject %<>% as.character()

```

```{r}
#| label: exp2-avgs


exp2.avgs <- exp2.clean %>%
    filter(match != "filler") %>%
    group_by(grammatical, attractor_num, att_type) %>%
    summarise(
        successes = sum(response_yes == 1, na.rm = TRUE),
        N = sum(!is.na(response_yes)),
        .groups = "drop"
    ) %>%
    mutate(ci_mat = purrr::pmap(
        list(successes, N),
        ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
    )) %>%
    mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
    unnest(ci_mat) %>%
    mutate(
        p_hat = successes / N,
        lwr   = lwr.ci,
        upr   = upr.ci
    ) %>%
    select(grammatical, attractor_num, att_type, successes, N, p_hat, lwr, upr)

exp2.avgs.filler <- exp2.clean %>%
    filter(match == "filler") %>%
    group_by(grammatical, attractor_num, att_type) %>%
    summarise(
        successes = sum(response_yes == 1, na.rm = TRUE),
        N = sum(!is.na(response_yes)),
        .groups = "drop"
    ) %>%
    mutate(ci_mat = purrr::pmap(
        list(successes, N),
        ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
    )) %>%
    mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
    unnest(ci_mat) %>%
    mutate(
        p_hat = successes / N,
        lwr   = lwr.ci,
        upr   = upr.ci
    ) %>%
    select(grammatical, attractor_num, att_type, successes, N, p_hat, lwr, upr)


```

```{r}
#| label: process-turklogacev2024
#| output: FALSE
source("turklogacev24.R")
```


```{r}
#| label: exp2-text-inputs

# I want accuracy, not the response yes
exp2.avgs.filler %<>%
    mutate(old.lwr = lwr, old.upr = upr) %>%
    mutate(
        p_hat = if_else(grammatical == "ungrammatical", 1 - p_hat, p_hat),
        lwr = if_else(grammatical == "ungrammatical", 1 - old.upr, old.lwr),
        upr = if_else(grammatical == "ungrammatical", 1 - old.lwr, old.upr)
    ) %>%
    select(-old.lwr, -old.upr)


exp2.nsubj <- exp2$subject %>%
    unique() %>%
    length()

exp2.nsubj.nontr <- exp2 %>%
    subset(natturk == "nat_non_turk") %>%
    .$subject %>%
    unique() %>%
    length()

exp2.nsubj.threshold <- 3

exp2.deletion <- round(100 * ((nrow(exp2.no.practice) - nrow(exp2.clean)) / nrow(exp2.no.practice)), 2)


exp2.meanage <- mean(asi(exp2.clean$age)) %>% round()
exp2.maxage <- max(asi(exp2.clean$age))
exp2.minage <- min(asi(exp2.clean$age))

# FILLER AVERAGES

exp2.avgs.filler %<>% mutate(text = paste0("M = ", round(p_hat, 2), ", CI = [", round(lwr, 2), ",", round(upr, 2), "]"))

exp2.avgs %<>% mutate(text = paste0("M = ", round(p_hat, 2), ", CI = [", round(lwr, 2), ",", round(upr, 2), "]"))


# Bind and set the desired x-axis order: rc → gen (current) → gen-tl (T&L 2024)
tl24.avgs$att_type <- "gen-tl"
all.avgs <- bind_rows(tl24.avgs, exp2.avgs) %>%
    dplyr::mutate(
        att_type = factor(att_type, levels = c("rc", "gen", "gen-tl"))
    )


```


## Participants

We recruited `r exp2.nsubj` undergraduate students to participate in the experiment in exchange for course credit. All participants were native Turkish speakers, with an average age of `r exp2.meanage` (range: `r exp2.minage` – `r exp2.maxage`). The experiment was carried out following the principles of the Declaration of Helsinki and the regulations concerning research ethics at Bogazici University. All participants provided informed consent before their participation and their identities were completely anonymised.

## Materials

The same materials were used with Exp1. We added items from @TurkLogacev2024 as an additional condition for nominal cases.

## Procedures

The same procedure with Experiment 1 was used.


## Analysis and Results


```{r}
#| label: exp2-models

options(mc.cores = parallel::detectCores())
theme_set(theme_bw(base_family = "Times"))


exp2.dfModel <- exp2.clean %>% subset(match != "filler")

exp2.dfModel %<>% mutate(exp = "current") %>% droplevels()
tl24.gen <- tl24.clean %>%
    subset(match != "filler") %>%
    mutate(att_type = "gen-tl") %>%
    droplevels()

exp2.all <- bind_rows(exp2.dfModel, tl24.gen)


exp2.all %<>%
    mutate(
        grammatical = factor(grammatical,
            levels = c("grammatical", "ungrammatical"),
            labels = c("Grammatical", "Ungrammatical")
        ),
        attractor_num = factor(attractor_num, # or attractor_num if that’s your column
            levels = c("singular", "plural"),
            labels = c("Singular", "Plural")
        ),
        att_type = factor(att_type, # or attractor_num if that’s your column
            levels = c("gen", "gen-tl", "rc"),
            labels = c("Gen-Current", "Gen-TL24", "RC")
        ),
    )

# Sum-code ±0.5 and give readable column names
C2 <- contr.sum(2) / 2

Cg <- C2
colnames(Cg) <- "Gram_minus_Ungram" # β > 0 ⇒ Ungram > Gram (in log-odds of YES)
Ca <- C2
colnames(Ca) <- "Plural_minus_Singular" # β > 0 ⇒ Plural > Singular (log-odds of YES)
C3 <- matrix(
    c(
        # RC vs both Gens
        -1, -1, 2, # contrast 1
        # Gen-Current vs Gen-TL24
        1, -1, 0 # contrast 2
    ),
    ncol = 2
)

# Normalize to mean-centered (sum to 0, length-scaled)
C3 <- apply(C3, 2, function(x) x / sum(abs(x)) * 2 / 3)

colnames(C3) <- c("RC_vs_Gens", "GenCurrent_vs_GenTL24")
rownames(C3) <- c("Gen-Current", "Gen-TL24", "RC")

# C3
contrasts(exp2.all$att_type) <- C3


contrasts(exp2.all$grammatical) <- Cg
contrasts(exp2.all$attractor_num) <- -Ca


make_priors_generic <- function(
    f_mean = 0, f_sd = 1,
    intercept_mean = 0.85, intercept_sd = 0.70,
    exp_rate = 1, lkj_eta = 2) {
    c(
        # Intercept
        set_prior(sprintf("normal(%g, %g)", intercept_mean, intercept_sd), class = "Intercept"),
        set_prior(sprintf("normal(%g, %g)", f_mean, f_sd), class = "b"),
        # Random-effect scales and correlations
        set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
        set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
    )
}

priors_uninformative <- make_priors_generic(
    f_mean = 0, f_sd = 1,
    exp_rate = 1,
    lkj_eta = 2
)



m.exp2.all <- brm(
    bf(response_yes ~ grammatical * attractor_num * att_type +
        (1 + grammatical * attractor_num * att_type | subject) +
        (1 + grammatical * attractor_num * att_type | item), decomp = "QR"),
    data = exp2.all,
    family = bernoulli(link = "logit"),
    prior = priors_uninformative,
    threads = threading(4),
    chains = 4, iter = 3000, warmup = 1000,
    init = 0, file = "m.exp2.all",
    seed = 1
)

```



```{r}
#| label: model-output-2

library(posterior)
library(glue)

coef_names2 <- list(
    # main effects
    gram = "b_grammaticalGram_minus_Ungram",
    attr = "b_attractor_numPlural_minus_Singular",
    type_rc_gen = "b_att_typeRC_vs_Gens",
    type_genpair = "b_att_typeGenCurrent_vs_GenTL24",

    # two-way interactions
    gram_attr = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular",
    gram_type_rc = "b_grammaticalGram_minus_Ungram:att_typeRC_vs_Gens",
    gram_type_gen = "b_grammaticalGram_minus_Ungram:att_typeGenCurrent_vs_GenTL24",
    attr_type_rc = "b_attractor_numPlural_minus_Singular:att_typeRC_vs_Gens",
    attr_type_gen = "b_attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24",

    # three-way interactions
    way3_rc = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens",
    way3_gen = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24"
)

post_int2 <- lapply(coef_names2, \(nm) summ_brms(m.exp2.all, nm))
txt2 <- lapply(post_int2, trip)
txt_p2 <- lapply(coef_names2, \(nm) fmt(p_gt0(m.exp2.all, nm), 2))



# Extract posterior draws
draws <- as_draws_df(m.exp2.all)

get_col <- function(draws, name) {
    if (!name %in% names(draws)) {
        stop(sprintf("Column '%s' not found. Available: %s", name, paste(head(names(draws), 10), collapse = ", ")))
    }
    draws[[name]]
}

# Coefficient names
b_ga_name <- "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular"
b_gat_rc_name <- "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens"
b_gat_gen_name <- "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24"

b_ga <- get_col(draws, b_ga_name)
b_gat_rc <- get_col(draws, b_gat_rc_name)
b_gat_gen <- get_col(draws, b_gat_gen_name)

# Compute effects per att_type level (Helmert-coded)
# Levels: RC_vs_Gens (+ for RC, - for both Gens); GenCurrent_vs_GenTL24 (+ for GenCurrent, - for GenTL24)
# RC: +0.5 on RC_vs_Gens, 0 on GenCurrent_vs_GenTL24
# Gen-Current: -0.25 on RC_vs_Gens, +0.5 on GenCurrent_vs_GenTL24
# Gen-TL24: -0.25 on RC_vs_Gens, -0.5 on GenCurrent_vs_GenTL24

eff_rc <- b_ga + 0.5 * b_gat_rc + 0.0 * b_gat_gen
eff_gencurrent <- b_ga - 0.25 * b_gat_rc + 0.5 * b_gat_gen
eff_gentl24 <- b_ga - 0.25 * b_gat_rc - 0.5 * b_gat_gen
prob_gt0 <- function(x) mean(x > 0)


# Summarize
predicted <- tibble(
    Condition = factor(c("RC", "Gen-Current", "Gen-TL24"),
        levels = c("RC", "Gen-Current", "Gen-TL24")
    ),
    mean = c(mean(eff_rc), mean(eff_gencurrent), mean(eff_gentl24)),
    l95 = c(quantile(eff_rc, 0.025), quantile(eff_gencurrent, 0.025), quantile(eff_gentl24, 0.025)),
    u95 = c(quantile(eff_rc, 0.975), quantile(eff_gencurrent, 0.975), quantile(eff_gentl24, 0.975)),
    P_gt0 = c(prob_gt0(eff_rc), prob_gt0(eff_gencurrent), prob_gt0(eff_gentl24)),
    P_lt0 = c(1 - prob_gt0(eff_rc), 1 - prob_gt0(eff_gencurrent), 1 - prob_gt0(eff_gentl24))
)

predicted <- predicted %>%
    mutate(
        # format p values: "<0.01", ">0.99", or rounded
        p_formatted = case_when(
            P_lt0 < 0.01 ~ "<0.01",
            P_lt0 > 0.99 ~ ">0.99",
            TRUE ~ paste0("=", sprintf("%.2f", round(P_lt0, 2)))
        ),

        # compose text string
        text = paste0(
            "M = ", round(mean, 2),
            ", CI = [", round(l95, 2), ", ", round(u95, 2), "]",
            ", P(<0) ", p_formatted
        )
    )


h <- hypothesis(
    m.exp2.all,
    c(
        # RC
        "(1*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular
      + (1/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens
      + 0*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0",
        # Gen-Current
        "(1*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular
      + (-1/6)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens
      + (1/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0",
        # Gen-TL24
        "(1*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular
      + (-1/6)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens
      + (-1/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0",
        # GenCurrent − GenTL24 difference
        "((2/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0"
    )
)

exp2_atts <- as_tibble(h$hypothesis) %>%
    transmute(
        contrast = c("RC", "Gen-Current", "Gen-TL24", "GenCurrent − GenTL24"),
        mean = Estimate, l95 = CI.Lower, u95 = CI.Upper,
        prob_lt0 = Post.Prob,
        text = paste0(
            "M = ", round(mean, 2),
            ", CI = [", round(l95, 2), ", ", round(u95, 2), "]",
            ", P(<0) = ",
            ifelse(is.na(prob_lt0), "NA",
                ifelse(prob_lt0 < 0.01, "<0.01",
                    ifelse(prob_lt0 > 0.99, ">0.99", round(prob_lt0, 2))
                )
            )
        )
    )

predicted <- exp2_atts %>%
    filter(contrast %in% c("RC", "Gen-Current", "Gen-TL24")) %>%
    transmute(
        Condition = recode(
            contrast,
            "RC" = "Attraction: Verbal\n(Current)",
            "Gen-Current" = "Attraction: Nominal\n(Current)",
            "Gen-TL24" = "Attraction: Nominal\n(Türk & Logačev 2024)"
        ),
        mean, l95, u95
    )

## 2) Pull the overall acceptability difference (Gen-Current vs Gen-TL24) from the model
fix <- posterior_summary(m.exp2.all, pars = "^b_") %>%
    as_tibble(rownames = "term")

# main effect of att_type GenCurrent_vs_GenTL24
genpair_row <- fix %>%
    filter(str_detect(term, "^b_att_type.*GenCurrent_vs_GenTL24$")) %>%
    slice(1)

coef_name <- genpair_row$term
# If this is empty, run: rownames(fixef(m.exp2.all)) and copy the exact name.

# 2) Compute P(<0) from draws
dr <- as_draws_df(m.exp2.all)
stopifnot(coef_name %in% names(dr))
prob_lt0 <- mean(dr[[coef_name]] < 0)

# 3) Build overall_df with prob and text
overall_df <- tibble(
    Condition = "Overall Acceptability:\nGen-Current − Gen-TL24",
    mean = genpair_row$Estimate,
    l95 = genpair_row$Q2.5,
    u95 = genpair_row$Q97.5,
)

## 3) Gen vs Gen difference in *attraction* from your exp2_atts (row 4)
diff_attr_df <- exp2_atts %>%
    filter(contrast == "GenCurrent − GenTL24") %>%
    transmute(
        Condition = "Attraction Difference:\nGen-Current − Gen-TL24",
        mean, l95, u95
    )

predicted_between <- bind_rows(diff_attr_df, overall_df, predicted)

overall_df <- overall_df %>%
    mutate(prob_lt0 = prob_lt0) %>%
    mutate(
        text = paste0(
            "M = ", round(mean, 2),
            ", CI = [", round(l95, 2), ", ", round(u95, 2), "]",
            ", P(<0) = ",
            ifelse(is.na(prob_lt0), "NA",
                ifelse(prob_lt0 < 0.01, "<0.01",
                    ifelse(prob_lt0 > 0.99, ">0.99", round(prob_lt0, 2))
                )
            )
        )
    )

predicted_between <- predicted_between %>%
    mutate(
        Condition = factor(
            Condition,
            levels = rev(c(
                "Attraction: Verbal\n(Current)", # A in RC
                "Attraction: Nominal\n(Current)", # A in Gen-Current
                "Attraction: Nominal\n(Türk & Logačev 2024)", # A in TL24
                "Attraction Difference:\nGen-Current − Gen-TL24", # Diff between Gens
                "Overall Acceptability:\nGen-Current − Gen-TL24" # Overall acceptability
            ))
        )
    )

p_between <- ggplot(predicted_between, aes(y = Condition, x = mean)) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray60") +
    geom_point(size = 3) +
    geom_errorbarh(aes(xmin = l95, xmax = u95), height = 0.15, linewidth = 0.7) +
    xlab(expression(paste("Effect Size (", beta, ")"))) +
    ylab(NULL) +
    theme_minimal(base_family = "Times") +
    theme(
        axis.text.y = element_text(size = 8),
        axis.text.x = element_text(size = 8),
        axis.title.x = element_text(size = 8),
        panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank()
    )

```


Participants showed high accuracy in both grammatical (`r get_value(exp2.avgs.filler, text, grammatical == "grammatical")`) and ungrammatical filler sentences (`r get_value(exp2.avgs.filler, text, grammatical == "ungrammatical")`), indicating that they understood the task and performed it reliably.

Figure 3 presents the overall means and credible intervals for 'yes' responses across experimental conditions, as well as the previous data from @TurkLogacev2024, which is quite similar to the magnitude of @LagoEtAl2019. As shown, in our study, participant gave more 'yes' responses to ungrammatical sentences with plural genitive-marked nominal attractors (`r get_value(all.avgs, text, grammatical == "ungrammatical", attractor_num == "plural", att_type == "gen")`) compared to their singular counterparts (`r get_value(all.avgs, text, grammatical == "ungrammatical", attractor_num == "plural", att_type == "gen")`).

However, similar increase in acceptability was not found with relative clause attractors (M = `r get_value(all.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "singular", att_type == "rc")` and `r get_value(all.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "plural", att_type == "rc")`, CI = [`r get_value(all.avgs, lwr, grammatical == "ungrammatical", attractor_num == "singular", att_type == "rc")`, `r get_value(all.avgs, upr, grammatical == "ungrammatical", attractor_num == "singular", att_type == "rc")`] and [`r get_value(all.avgs, lwr, grammatical == "ungrammatical", attractor_num == "plural", att_type == "rc")`, `r get_value(all.avgs, upr, grammatical == "ungrammatical", attractor_num == "plural", att_type == "rc")`] for singular and plural attractors, respectively). Participants rated grammatical sentences similarly independent of the attractor number or attractor type.

```{r}
#| label: exp2-condition-means
#| fig-cap: "Mean proportion of 'acceptable' responses by grammaticality, attractor number and attractor type. Error bars show 95% Clopper–Pearson confidence intervals. "
#| fig-width: 6
#| fig-height: 3
#|
exp2.gram.label <- c(
    "grammatical"   = "Grammatical\n(Singular Verb)",
    "ungrammatical" = "Ungrammatical\n(Plural Verb)"
)
exp2.att_type.label <- c(
    "rc"     = "Relative Clause\n(Current Paper)",
    "gen"    = "Gen-marked\n(Current Paper)",
    "gen-tl" = "Gen-marked\n(TL2024)"
)

# Plot: X = Attractor Type (ordered & labeled), facet = Grammaticality
all.avgs %>%
    ggplot(aes(
        x = att_type, y = p_hat,
        linetype = attractor_num, group = attractor_num
    )) +
    geom_point() +
    geom_line() +
    geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.12) +
    facet_wrap(~grammatical, labeller = as_labeller(exp2.gram.label)) +
    scale_x_discrete(labels = exp2.att_type.label, drop = FALSE) +
    xlab("Attractor Type") +
    ylab("Percentage 'acceptable'") +
    scale_y_continuous(labels = scales::percent) +
    scale_linetype_discrete(
        name = "Attractor Number",
        labels = c("Singular", "Plural")
    ) +
    theme_minimal(base_family = "Times") +
    theme(
        legend.position = "bottom",
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(size = 9),
        axis.text.y = element_text(size = 9),
        axis.text.x = element_text(size = 9),
        axis.title.x = element_text(size = 9),
    )
```

Our models also showed similar results, assuming a Bernoulli logit link. Our main research question was whether verbal attractors induced attraction effects. We also wanted to check whether within-experiment statistics affected the attraction magnitudes, i.e. the effect of presence of verbal attractors on nominal attractors. To that end, we included genitive marked nominals from data from our experiment and @TurkLogacev2024. The model was fitted to the binary *yes/no* responses and included fixed effects for Grammaticality, Attractor Number, and Attractor Type and their interaction, along with random intercepts and slopes for both subjects and items.

We present posterior summaries of estimated regression effects from our model in Figure 4.  We found a robust attraction in both nominal attractor cases, with strongly negative effects for our nominal items (`r get_value(exp2_atts, text, contrast == "Gen-Current")`) and items from @TurkLogacev2024 (`r get_value(exp2_atts, text, contrast == "Gen-TL24")`).  More importantly, our model found no evidence for an attraction in verbal attractor conditions (`r get_value(exp2_atts, text, contrast == "RC")`), verifying our observations in the descriptive statistics.  The evidence for a difference in magnitude of attraction between the two genitive types was not found (`r get_value(exp2_atts, text, contrast == "GenCurrent − GenTL24")`), suggesting the within-experimental distribution did not affect attraction magnitudes.  Finally, we found strong evidence for a decreased overall acceptability for nominal items in our experiment (`r get_value(overall_df, text)`), suggesting the within-experimental distribution did affect overall acceptability, but not attraction.


```{r}
#| label: exp2-fixed-effects
#| fig-cap: "Posterior summaries of attraction-related effects. Points indicate posterior means, and horizontal bars show 95% credible intervals on the log-odds (β) scale. Attraction was estimated as the interaction between grammaticality and attractor number within each attractor type. Negative values indicate stronger attraction (a reduced ungrammaticality penalty in plural-attractor conditions). Dashed line denotes zero (no effect)."
#| fig-width: 6
#| fig-height: 2

p_between
```


## Discussion


Experiment 2 tested whether the reason we did not find attraction effects in Experiment 1 was due to the lack of attraction-inducing conditions.  Our results showed that attraction effects in verbal attractor condition, purely phonological overlap, did not surface even when there are robust attraction-inducing trials.  Participants reliably rejected ungrammatical sentences with verbal attractors regardless of attractor number.

Our results and between experiment comparison showed that within-experiment statistics, i.e. exposure to verbal attraction conditions attraction items, did not substantially reduced the magnitude of the attraction effects.  However, the overall acceptability in our nominal attractor elements were reduced compared to the trials from @TurkLogacev2024.  This is inline with previous findings that shows participants' judgments within the experiment are modulated by the distribution of trials.  Interestingly, previous studies achieved this with instructions or filler elements [@HammerlyEtAl2019; @ArehalliWittenberg2021].  We show that the experimental conditions and the presence of an effect within a subset of conditions also plays a role in modulating overall acceptability.


# General Discussion

In two high-powered speeded acceptability judgment experiments, we tested whether pure phonological overlap between agreement morphemes can elicit agreement attraction. Our goal was to evaluate previous accounts that attribute attraction to accidental or non-accidental syncretism between forms that can serve as agreement controllers. Turkish provides a useful test case because the plural suffix -lAr appears both on verbs and on nouns, but only nominal -lAr can control agreement. If phonological overlap alone can activate controller-relevant cues, then plural-marked verbs embedded in reduced relative clauses should induce attraction effects even though they cannot syntactically control agreement.

Across both experiments, we found that Turkish attraction is determined by being a potential controller rather than merely resembling one. Participants did not produce or endorse attraction errors in sentences containing verbal attractors, and this absence of attraction persisted even when the same participants showed robust attraction with nominal attractors in the same session.

These results indicate that attraction depends on abstract feature overlap with potential controllers, not on surface-form similarity. This pattern converges with prior results in English and Turkish that failed to find attraction for pseudoplural or phonologically plural forms [@BockEberhard1993; @HaskellMacDonald2003; @NicolEtAl:2016], and stands in contrast to findings from Russian [@Slioussar2018].

In @Slioussar2018, genitive-marked singular nouns that were homophonous with nominative plurals elicited greater attraction effects than their genitive-plural counterparts. This is striking because the relevant nouns lacked a plural feature that could percolate or serve as a retrieval cue. The effect was therefore interpreted as evidence that comprehenders can use phonological form to activate abstract agreement features. However, it is important to note that the evidence for phonological attraction in Russian rests on a small empirical base. The production and comprehension experiments in [@Slioussar2018] included only 32 participants each, and the attraction effects were derived from a small number of error trials (13 in production and 18 in comprehension). Given the low number of critical observations, such effects are vulnerable to sampling variability and may not generalize beyond that dataset.

<!-- Simulations with comparable sample sizes suggest that s tudies of this scale would have limited power to detect differences as small as 5 % in acceptability, raising the possibility that the reported effects may reflect Type I error or unstable estimation. -->

The high-powered Turkish results challenge that interpretation. Despite identical surface overlap between verbal and nominal plural morphology, phonological similarity alone did not yield attraction. This cross-linguistic contrast suggests that form-based activation of agreement features is not a universal property of the parsing system but, at best, depends on language-specific mappings between morphology and syntactic function [@DillonKeshev2024].

A more plausible account is that attraction is modulated by the availability of morphosyntactic features that can signal controllerhood. Syncretism contributes to attraction only when one of the syncretic forms can legitimately control agreement or share features with the target. In other words, it is not form overlap per se, but feature ambiguity that matters. This interpretation aligns with cross-linguistic findings showing that attraction is strongest when the attractor bears case or number morphology that is sometimes associated with subjects or agreement controllers [@LagoEtAl2019; @BhatiaDillon2022; @BleotuDillon2024; @HartsuikerEtAl2003]. Earlier formulations of these models left open whether 'looking like' a controller or 'being able to be' a controller was critical. The present results favor the latter: only morphologically licensed controllers engage in attraction.

<!-- Finally, the comparison between Experiments 1 and 2 shows that while overall acceptability is sensitive to the statistical distribution of grammatical and ungrammatical items, the underlying attraction mechanism is not. This dissociation supports the view that attraction arises from structured retrieval cues rather than from global response biases or shallow form-matching strategies. -->

# References {.unnumbered}

\newcommand{\doi}[1]{\href{http://dx.doi.org/#1}{http://dx.doi.org/#1}}
\begingroup
\raggedright
\singlespacing
::: {#refs}
:::
\endgroup
