---
title: "(In)sensitivity to surface-level heuristics: A case from Turkish verbal attractors"
# subtitle: "Within-experiment statistics in agreement attraction"
author:
  - name: Utku Turk
    email: utkuturk@umd.edu
    affiliations:
        - id: umd
          name: University of Maryland, College Park
          department: Linguistics
          address: Marie Mount Hall
          city: College Park
          state: MD
          postal-code: 20742
    acknowledgements: "This project heavily benefitted from discussions with Pavel Logacev. I am also thankful first and foremost Ellen Lau, along with Colin Phillips and Brian Dillon for their comments on the manuscript."
    attributes:
        corresponding: true
    # note: This is the first author footnote.
abstract: |
  Linguistic illusion literature has stimulated ongoing debate on what type of information can be used to access memory representations.  Prior work tests whether structural, semantic, or discourse cues guide subject-verb dependencies; it remains unclear whether native speakers rely on phonological information as a retrieval cues for memory access during dependency resolution, such as person agreement.  Traditionally, accidental phonological resemblance to having a plural ending as in /s/ sound in *course* was found to not induce erroneous plural agreement, meanwhile, phonological resemblance that correlates with controllerhood amplifies attraction given an already present plural morpheme.  In apparent contradiction to this generalization, Slioussar (2018) proposed that memory search for a subject in Russian sentences can be mediated through an accidental phonological resemblance.  Given the theoretical importance of this proposal and the lack of comparable effects in other languages, we test whether phonological overlap can elicit erroneous agreement in Turkish, where the plural morpheme -lAr surfaces on both nouns and verbs. Turkish provides a critical test: both verbal elements and nominal elements can surface as subjects, but only nominal plural -lAr controls verbal agreement. Two speeded acceptability studies show no attraction from plural-marked verbs (Exp. 1 N = 80; Exp. 2 N = 95) but robust attraction from genitive plural nouns. We report a first-of-its-kind dissociation under minimal manipulation: verbal attractors that can be subjects yet cannot control agreement do not induce attraction, whereas genitive plural nouns that can be subjects and control in other environments do. To our knowledge this pattern has not been shown in any other language, and it constrains cue-based retrieval by tying attraction to abstract controller features rather than surface phonology. 
keywords:
  - form-sensitivity
  - memory
  - agreement attraction
  - linguistic illusions
  - sentence processing
date: last-modified
bibliography: bibliography.bib
format:
  elsevier-pdf:
    pdf-engine: xelatex
    include-in-header:
      - preamble.tex
    keep-tex: true
    # latex-clean: false
    # latex-min-runs: 3
    journal:
      name: Cognition
    #   formatting: preprint
      model: 3p # Don't set a model with preprint
      cite-style: authoryear
  html:
    embed-resources: true
    toc: true
filters:
  - wordcount
wordcount:
  count-code-blocks: false
  count-inline-code: false
execute:
  echo: false
  message: false
  warning: false
editor_options: 
  chunk_output_type: console
---


```{r}
#| label: setup

set.seed(01110011)
library(tidyverse)
library(brms)
library(data.table)
library(gdata)
library(magrittr)
library(DescTools)
select <- dplyr::select
library(lingglosses)
```


```{r}
#| label: functions

read_experimental_data <- function(fname, subj_offset = 0, item_offset = 0, verbose = F) {
    data <- read.csv(fname,
        header = F,
        comment.char = "#",
        encoding = "UTF-8",
        col.names = paste0("V", seq_len(11)),
        fill = TRUE,
        stringsAsFactors = FALSE
    )
    colnames(data) <- c("Time", "MD5", "ControllerType", "SentenceNoInStimFile", "Element", "exp_condition", "item", "Sentence", "Question", "Answer", "RT")

    subject_id <- with(data, {
        as.integer(as.factor(paste(Time, MD5)))
    })
    data$item[data$exp_condition == "intro" | data$exp_condition == "practice"] <- 0
    data$item_num <- as.integer(data$item)
    data$subject <- sprintf("S[%d]", subject_id + subj_offset)
    data$item <- sprintf("I[%d]", data$item_num + item_offset)

    df_forms <- data %>%
        subset(ControllerType != "DashedAcceptabilityJudgment") %>%
        gdata::drop.levels()
    data %<>% subset(ControllerType == "DashedAcceptabilityJudgment")

    age <- df_forms %>%
        dplyr::filter(Sentence == "age") %>%
        dplyr::select(subject, age = Question)
    natturk <- df_forms %>%
        dplyr::filter(Sentence == "natturk") %>%
        dplyr::select(subject, natturk = Question) %T>% {
            .$natturk %<>% recode(male = "nat_turk", female = "nat_non_turk")
        }
    forms <- dplyr::left_join(age, natturk, by = "subject")

    stopifnot(nrow(data) %% 2 == 0)
    rows_stim <- data[c(T, F), ]
    rows_resp <- data[c(F, T), ]
    stopifnot(all(is.na(rows_stim$RT)))

    data <- rows_resp %>%
        left_join(forms) %>%
        dplyr::select(-MD5, -Time, -ControllerType, -Sentence, -Element) %>%
        dplyr::rename(ResponseCorrect = Answer, Response = Question) %>%
        dplyr::select(-ResponseCorrect)
    data %<>% group_by(subject) %>% mutate(trial_no = seq(subject))
    data %<>% mutate(late_response = (Response == "NULL"), Response = ifelse(late_response, NA, as.character(Response)))

    responses <- c(yes = "İYİ (P'ye basınız)", no = "KÖTÜ (Q'ya basınız)")
    data$Response %<>% as.character() %>% enc2native()
    stopifnot(all(data$Response %in% responses | is.na(data$Response)))

    data$response_yes <- ifelse(grepl("P'ye", data$Response), T,
        ifelse(grepl("Q'ya", data$Response), F, NA)
    )
    if (verbose) {
        print(with(data, table(Response, response_yes)))
    }
    data %<>% dplyr::select(-Response)
    data
}


exclude_bad_subjects <- function(data_to_clean, accuracy_threshold = 0.25, rt_below = 200, rt_upper = 4999, verbose = F) {
    avg_by_subj <- data_to_clean %>%
        group_by(
            subject, experiment, condition,
            grammatical, verb_num, attractor_num
        ) %>%
        summarize(
            avRT = mean(RT),
            p_yes = mean(response_yes, na.rm = T),
            N = sum(!is.na(response_yes))
        )

    avg_by_subj_wide <- avg_by_subj %>%
        mutate(expcond = paste(experiment, condition, sep = "_")) %>%
        ungroup() %>%
        dplyr::select(
            -experiment, -condition, -avRT, -N,
            -grammatical, -verb_num, -attractor_num
        ) %>%
        tidyr::spread(expcond, p_yes) %>%
        mutate(delta_dc = AgrAttr_d - AgrAttr_c)

    bad_subjects <- subset(avg_by_subj_wide, delta_dc <= accuracy_threshold) %>% .$subject
    data_clean <- data_to_clean %>% subset(!subject %in% bad_subjects)

    data_clean %<>% filter(RT < rt_upper & rt_below < RT)
    if ("natturk" %in% colnames(data_clean)) {
        data_clean %<>% subset(natturk == "nat_turk")
    }

    if (verbose) {
        print(with(data_clean, table(exp_condition, response_yes)))
        print(sprintf("number of bad subjects: %f", length(bad_subjects)))
    }

    data_clean
}

no_null_no_practice <- function(data_to_clean) {
    data_to_clean %<>% subset(exp_condition != "practice") %>% subset(!is.na(response_yes))
}

asi <- function(x) {
    as.integer(x)
}
asf <- function(x) {
    as.factor(x)
}
asc <- function(x) {
    as.character(x)
}

get_value <- function(df, col, ...) {
    vals <- df %>%
        filter(...) %>%
        pull({{ col }})
    if (is.numeric(vals)) {
        vals <- round(vals, 2)
    } else {
        vals <- as.character(vals)
    }

    vals
}

exclude_bad_subjects_8 <- function(data_to_clean, accuracy_threshold = 0.25, rt_below = 200, rt_upper = 4999, verbose = F) {
    avg_by_subj <- data_to_clean %>%
        group_by(
            subject, experiment, condition,
            grammatical, verb_num, attractor_num, att_type
        ) %>%
        summarize(
            avRT = mean(RT),
            p_yes = mean(response_yes, na.rm = T),
            N = sum(!is.na(response_yes))
        )

    avg_by_subj_wide <- avg_by_subj %>%
        mutate(expcond = paste(experiment, condition, sep = "_")) %>%
        ungroup() %>%
        dplyr::select(
            -experiment, -condition, -avRT, -N,
            -grammatical, -verb_num, -attractor_num, -att_type
        ) %>%
        tidyr::spread(expcond, p_yes) %>%
        mutate(delta_gen_dc = AgrAttr_gen_d - AgrAttr_gen_c, delta_rc_dc = AgrAttr_rc_d - AgrAttr_rc_c)

    bad_subjects_gen <- subset(avg_by_subj_wide, delta_gen_dc <= 0.25) %>% .$subject
    bad_subjects_rc <- subset(avg_by_subj_wide, delta_rc_dc <= 0.25) %>% .$subject
    data_clean <- data_to_clean %>% subset(!subject %in% bad_subjects_gen | !subject %in% bad_subjects_rc)

    data_clean %<>% filter(RT < rt_upper & rt_below < RT)
    if ("natturk" %in% colnames(data_clean)) {
        data_clean %<>% subset(natturk == "nat_turk")
    }
    if (verbose) {
        print(with(data_clean, table(exp_condition, response_yes)))
        print(sprintf("number of bad subjects: %f", length(bad_subjects_gen) + length(bad_subjects_rc)))
    }

    data_clean
}

```


# Introduction

Human sentence processing draws on abstract grammatical features and on heuristics that exploit surface regularities, such as plausibility [@SpeerClifton1998], frequency [@LauEtAl2007], and task-specific factors [@LauraMalsbug24; @ArehalliWittenberg2021; @HammerlyEtAl2019; @LogacevVasishth2016].  We focus on one such heuristic: over-reliance on surface form, evidenced when phonological similarity between sentence constituents is observed to modulate performance [@AchesonMacDonald2011;@KushEtAl2015;@CopelandRadvansky2001; @RastleDavis2008]. Prior work shows reliable slowdowns and comprehension accuracy costs due to surface-form overlap, but it is unresolved whether this heuristic penetrates dependency resolution itself--including subject-verb agreement, pronoun resolution, or the licensing of negative polarity items--beyond general effects on reading ease and memory. The few studies that bear directly on subject-verb agreement exhibit contradictory findings [@BockEberhard1993;@Slioussar2018].


A central question for understanding human cognition is what information is encoded and later available to memory during comprehension, and how faithful these encodings are to the input. 'Good-Enough' and noisy channel accounts argue that detailed analyses are not always maintained when heuristics suﬀice, creating the opportunity for surface regularities to affect judgments [@FerreiraEtAl2002]. More specifically, general cue-based retrieval approaches hold that constituents are stored with detailed abstract features and later accessed by matching retrieval cues, and that erroneous parses can occur when features conflict or interfere. However, it remains open whether phonological codes are used as such cues during syntactic dependency building [@LV05], or even whether they persist long enough to do so. Determining whether surface-form overlap modulates dependency resolution provides a window into what human cognition counts as diagnostic information for retrieving dependency controllers and how faithful the stored representations are.

Agreement is an ideal case study because its computations are known to be sensitive to feature overlap. Classic findings demonstrate systematic errors in establishing number agreement between a verb and its agreement controller when an NP with a different number (the attractor) interferes, observed when speakers produce sentences like (\ref{og}) or misclassify them as acceptable [@BockMiller:1991; @PearlmutterGarnseyBock:1999]. 

```{=latex}
\begin{exe}
\ex[*]{\label{og} The player on the courts are tired from a long-game.}
\end{exe}
```

Despite much research on what factors modulate agreement errors, the role of phonology remains unclear. Pseudoplural attractors whose phonological offset matches the plural suffix (e.g. *course*) do not increase agreement errors in production [@BockEberhard1993]. Phonological overlap effects have been observed in other cases, but many of them involve additional shared morphological features [@HartsuikerEtAl2003; @LagoEtAl2019 ;@BleotuDillon2024], although not all [@Slioussar2018]. This raises the possibility that surface form affects the formation of agreement dependencies not directly through the use of number form as a retrieval cue, but indirectly, when the surface form is one that is more likely to be realized on agreement controllers.

Here we test this hypothesis by utilizing the surface-form overlap between the verbal and nominal morphological reflexes of agreement that happens to occur in Turkish. Turkish uses the same surface suﬀix, *-lAr*, for plural marking on nouns and for plural agreement on finite verbs.  Crucially, strings bearing verbal *-lAr* can occur in subject position, yet they never control finite clause agreement; only nominal plurals do. These properties allow a direct test of whether form overlap alone causes agreement errors, or whether form overlap effects must be mediated by an element that can in principle serve as an agreement controller (true of nouns but not verbs). Across two high-powered speeded acceptability experiments in Turkish we find that plural marking on an embedded verbal attractor does not increase acceptance of plural agreement on the matrix verb; such effects are only observed when the plural marker appears on a non-subject noun attractor.  These results indicate that surface-form overlap alone does not function as a retrieval cue for agreement in Turkish. Dependency resolution appears to rely on abstract features and structural relations, with phonology influencing processing primarily outside of retrieval.


## Background

Agreement has been a central domain of investigation for language processing research on memory. Across the world's languages, morphological marking of agreement between a sentential verb and one or more of its arguments—termed the agreement controller—is extremely common; one survey reports that native speakers from 296 of out 378 languages surveyed exhibit systematic agreement between the verb and another constituent(s) [@WALS]. However, this agreement process is not always reliable. In their seminal work, @BockMiller:1991 showed that participants produce reliably more erroneous non-controller-matching plural verb forms in English when an embedded 'attractor' noun was plural—for example, producing a plural-marked continuation such as are instead of is occurs more often after (\ref{true-pl}) than (\ref{true-sg}). The effect of the number mismatching attractor, agreement attraction, has also been found to be robust in comprehension [@NicolEtAl1997; @PearlmutterGarnseyBock:1999] of such sentences in various languages, including Arabic [@TuckerEtAl:2015], Armenian [@AvetisyanEtAl:2020], Hindi [@BhatiaDillon2022], Spanish [@LagoEtAl2015], Russian [@Slioussar2018], and Turkish [@LagoEtAl2019;@TurkLogacev2024;@Ulusoy2023].  

```{=latex}
\begin{exe}
\ex \label{initial}
\begin{xlist}
    \ex \label{true-sg} {Singular Attractor} \\ The {player} on the {court} \ldots{}
    \ex \label{true-pl} {Plural Attractor} \\ The {player} on the {courts} \ldots{}
\end{xlist}
\end{exe}
```

Many studies have investigated the various syntactic and semantic factors which make agreement errors more or less likely. These factors include hierarchical distance [@HatsuikerEtAl2001; @NicolEtAl1997; @Kaan2002], linear distance [@Pearlmutter2000; @BockCutting1992], semantic interactions of nouns involved [@Eberhard1999; @ViglioccoEtAl95; @HumphreysBock2005], and syntactic category of the phrase containing the attractor [@BockMiller:1991; @BockCutting1992]. One widely accepted set of accounts that attempted to capture these error profiles is called retrieval based theories [@LV05;@WagersEtAl:2009]. In these accounts, participants have a faithful representation of the constituents they process, and that errors arise because they are misled by the memory mechanisms they use to identify the agreement controller. Under this approach, phrases are encoded in a content-addressable memory as bundles of features called *chunks* which include information like, number, gender, and syntactic information [@SmithVasishth2020].  Participants predict the number of the verb based on the noun phrases they process while reading the previous noun phrases.  In grammatical sentences with singular verb agreement, the number prediction and the verb number match, which causes no processing difficulty.  In contrast, when participants fail to find the predicted number morphology on the verb, a memory-retrieval process is initiated.  This process activates the search for a chunk matching relevant cues for agreement controller.  

What is the characteristics of cues which are found useful to be encoded? One line of work manipulated overt case marking on attractors to test whether morphophonological case is used for dependency resolution. For example, @HartsuikerEtAl2003 used the syncretic homophony between nominative/accusative and singular/plural forms of feminine determiners in German, comparing these ambiguous forms to distinctly marked dative forms. Participants produced more agreement errors when the preambles contained two noun phrases whose determiners were ambiguously marked (*die*), compared to cases where the attractor case could be distinguished by form alone (*den*). Furthermore, this additive effect was limited to feminine nouns, the only gender showing nominative–accusative syncretism in plural forms, while nouns of other grammatical genders showed the base effect of plural.

However, results from other languages with overt case marking are more mixed. @FrankEtAl2010, working in French, compared unambiguously accusative-marked attractors to NPs with no overt case marking and found that unambiguous case increased attraction, contrary to the simple prediction that reducing ambiguity should reduce interference. @AvetisyanEtAl:2020 similarly reported that unambiguous case marking in Armenian did not reliably modulate either reading times or attraction errors. These findings suggest that the mere presence of distinct case morphology is not sufficient to predict interference, and that language specific distributions or heuristic use of case may also be involved.

A second line of work tests phonological overlap that does not itself change the syntactic analysis. @BockEberhard1993 tested whether attractors that only sound plural, pseudoplural singular attractors such as *course*, increase agreement errors compared to true plural nouns, such as *courts* in (\ref{true-pl}). They reasoned that if participants rely on phonological cues rather than abstract features, words ending with plural-like sounds (/s/ or /z/) should behave like true plurals. In their preamble completion study, they found that pseudoplural attractors did not induce agreement errors, which argues against a purely phonology-driven account of attraction in English.

In contrast, @Slioussar2018 reported a robust contribution of surface-form overlap to agreement in Russian. In Russian, a subset of genitive singular nouns is homophonous with nominative plural forms, while genitive plural forms are not ambiguous in this way. In a series of production and comprehension experiments, @Slioussar2018 showed that sentences with a singular genitive attractor whose form overlaps with nominative plural yielded more plural completions, faster reading times at the plural verb and higher rates of acceptability compared to the sentences with unambiguous genitive plural attractors. @Slioussar2018 took these results to be an evidence for a retrieval process in which the search for a controller is mediated through phonological form and relevant features like +NOM and +PL can be activated. However, mixed previous findings in case-syncretism literature and English pseudoplural casts a shadow on this explanation.

An alternative account that does not depend on activation of relevant features by phonology would depend on encoding of distributional facts as statistical heuristics.  In such an account, instead of relying on activation of features through a phonological route, participants would probabilistically associate certain strings, such as genitive marked NP or overt D head, with being an agreement controller.  Indeed, similar explanations for syncretism or subject-likeness phenomenon has been reported.  For example, @LagoEtAl2019 argued that participants can retrieve a noun as the controller if the noun is marked with a case marking that may sometimes control agreement in a language even if that is not the case for the specific sentence.  They used Turkish genitive case, which can control the agreement in embedded sentences but not in matrix sentences.  They took the presence of attraction effects in Turkish as an indication that Turkish speakers utilize overt genitive-case's association with subjecthood.  In a sense, phonological, not functional, syncretism between the marking on the nominal modifier and the embedded subject resulted in attraction.  A similar account from Dillon and colleagues was pushed for sensitivity for looking like a controller in languages like Romanian and Hindi [@BhatiaDillon2022; @BleotuDillon2024].  For instance, @BleotuDillon2024 manipulated whether the attractor surfaces with a determiner or in its bare form.  Importantly, they note that only nouns with determiners can control agreement in Romanian. They found that Romanian attractors only induced attraction effects when both attractor and the head surfaced with a determiner.  They took these results to suggest that participants associated presence of a determiner or related feature with the agreement controller, and attraction only surfaces when subject heads and the attractor look alike.  Similarly, @SchlueterEtAl2018 argue that and can cause agreement attraction effects in English even when it does not create a plurality because it is associated with the plural feature statistically.  Such explanations are based on the assumption that the match between a cue and a chunk does not have to be categorical, but it can be influenced by surface level statistical association [@EngelmannEtAl2019].

A similar account can also be proposed for Russian findings.  Genitive marked nouns can be subjects in negative inversion constructions in Russians.  However, when they are subjects, they cannot control the agreement.  In other cases, they can be the controller of number or gender marking on adjectival relative clauses.  Given this possibility of an alternative account, the contention of initial findings of @BockEberhard1993, and the theoretical importance of the empirical generalization, we test a stronger version of the phonological modulation hypothesis: whether overlap in overt plural morphology that matches the agreement suffix in both form and plural semantics, while being syntactically unable to serve as an agreement controller, can by itself give rise to attraction in two high-powered speeded acceptability judgment experiments.  To this end we use Turkish, a language where verbal and nominal plural marking share the same surface form, the suffix *–lAr*.  We use reduced relative clause (RRC) structures, in which the verb with the plural marking alone can appear as the attractor (\ref{rrc-intro}). Importantly, Turkish *–lAr* syncretism here is not feature-ambiguous (as in cases of syncretism); it is a form-only overlap that does not share possible argument status with a possible controller. Even when the RRC can surface without its head as the subject, they cannot control the agreement (\ref{rrc-subject}).

```{=latex}
\begin{exe}
\ex \label{rrc-intro}
\gll Gör-dük-ler-i çocuk koş-tu-(*lar).\\
go-NMLZ-PL-POSS kid[NOM] run-PST-(*PL)\\
\glt `The kid that (they) saw ran.'
\ex \label{rrc-subject}
\gll Gör-dük-ler-i koş-tu-(*lar).\\
go-NMLZ-PL-POSS run-PST-(*PL)\\
\glt `(The kid) that (they) saw ran.'
\end{exe}
```

In Experiment 1, we tested the form hypothesis by comparing sentences with verbal attractors to sentences with canonical nominal attractors in Turkish. Experiment 2 then tested the form hypothesis more directly by only using verbal attractors. We expected that if surface-overlap can modulate relevant memory representations for dependency resolutions, we would see similar attraction results with nominal and verbal attractors.   However, if participants are tracking an higher order cue that is relevant for being a possible controller, then the verbal attractors, due to their inability to control agreement, would not introduce agreement attraction effects even though their high morpho-phonological similarity.

Across both experiments, we found no evidence that verbal *–lAr* induces attraction, even when canonical nominal attractors are present in the same session.  This pattern aligns with prior findings in general attraction literature and Turkish agreement attraction, namely surface-form overlap alone does not derive agreement illusions.  Rather, attraction appears to depend on abstract feature overlap between potential controllers and agreement probes, and possibly statistical associations between the strings and their controllers.  In this light, findings of @Slioussar2018 are best analyzed as a possible increased association between genitive marking and possible subjecthood and being an agreement controller.  By doing so, we hope to clarify how cue-mechanisms are employed and the role of phonological overlap in sentence processing.

# Experiment 1: Testing Surface-Form Overlap

```{r}
#| label: exp2-data-prep

exp2 <- read_experimental_data("../data/results_8cond.txt", subj_offset = 2500, item_offset = 2500)

exp2 %<>% mutate(exp_condition = case_when(
    exp_condition == "filler" & item_num <= 120 ~ "filler_ung",
    exp_condition == "filler" & item_num >= 121 ~ "filler_g",
    exp_condition == "practice" ~ "practice",
    exp_condition == "condition_gen_b" ~ "condition_gen_b",
    exp_condition == "condition_gen_a" ~ "condition_gen_a",
    exp_condition == "condition_gen_c" ~ "condition_gen_c",
    exp_condition == "condition_gen_d" ~ "condition_gen_d",
    exp_condition == "condition_rc_b" ~ "condition_rc_b",
    exp_condition == "condition_rc_a" ~ "condition_rc_a",
    exp_condition == "condition_rc_c" ~ "condition_rc_c",
    exp_condition == "condition_rc_d" ~ "condition_rc_d"
))


exp2.conditions <- data.frame(
    exp_condition = c("practice", "condition_gen_a", "condition_gen_b", "condition_gen_c", "condition_gen_d", "condition_rc_a", "condition_rc_b", "condition_rc_c", "condition_rc_d", "filler_ung", "filler_g"),
    experiment = c("practice", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "AgrAttr", "filler", "filler"),
    condition = c("practice", "gen_a", "gen_b", "gen_c", "gen_d", "rc_a", "rc_b", "rc_c", "rc_d", "filler_ung", "filler_g"),
    grammatical = c("practice", "ungram", "gram", "ungram", "gram", "ungram", "gram", "ungram", "gram", "ungram", "gram"),
    verb_num = c("practice", "pl", "sg", "pl", "sg", "pl", "sg", "pl", "sg", "sg", "pl"),
    attractor_num = c("practice", "pl", "pl", "sg", "sg", "pl", "pl", "sg", "sg", "filler", "filler"),
    match = c("practice", "mismatch", "mismatch", "match", "match", "mismatch", "mismatch", "match", "match", "filler", "filler"),
    att_type = c("practice", rep("gen", 4), rep("rc", 4), "filler", "filler"),
    stringsAsFactors = T
)

exp2 %<>% left_join(exp2.conditions, by = "exp_condition")

exp2.no.practice <- exp2 %>% subset(exp_condition != "practice")

# accuracy: 0.25
# rt_below: 200
# rt_upper: 4999
exp2.clean <- exclude_bad_subjects_8(
    exp2,
    accuracy_threshold = 0.25,
    rt_below = 200,
    rt_upper = 4999
)

exp2.clean %<>% no_null_no_practice(.)

stopifnot(exp2.clean %>% subset(is.na(response_yes)) %>% nrow() == 0)

# DIFF DATA =====
exp2.diff <- dplyr::anti_join(exp2, exp2.clean) %>%
    filter(exp_condition != "practice")

exp2.clean$isGram <- ifelse(exp2.clean$grammatical == "ungram", F, T)
exp2.clean$p_acc <- with(exp2.clean, response_yes & isGram)
exp2.clean %<>% mutate(ResponseCorrect = (response_yes == (grammatical == "gram")))

# Merge

exp2.clean %<>% ungroup() %>%
    dplyr::select(
        source = experiment,
        grammatical,
        attractor_num,
        att_type,
        match,
        age,
        # condition,
        subject,
        trial_no,
        item,
        response_yes,
        RT,
        ResponseCorrect
    )
exp2.clean$experiment <- "Experiment 1"
exp2.clean$grammatical %<>% dplyr::recode(gram = "grammatical", ungram = "ungrammatical")
exp2.clean$attractor_num %<>% dplyr::recode(pl = "plural", sg = "singular")
exp2.clean$att_type %<>% dplyr::recode(gen = "gen", rc = "rc")
exp2.clean$item %<>% as.factor()
exp2.clean$subject %<>% as.character()

```

```{r}
#| label: exp2-avgs


exp2.avgs <- exp2.clean %>%
    filter(match != "filler") %>%
    group_by(grammatical, attractor_num, att_type) %>%
    summarise(
        successes = sum(ResponseCorrect == TRUE, na.rm = TRUE),
        N = sum(!is.na(ResponseCorrect)),
        .groups = "drop"
    ) %>%
    mutate(ci_mat = purrr::pmap(
        list(successes, N),
        ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
    )) %>%
    mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
    unnest(ci_mat) %>%
    mutate(
        p_hat = successes / N,
        lwr   = lwr.ci,
        upr   = upr.ci
    ) %>%
    select(grammatical, attractor_num, att_type, successes, N, p_hat, lwr, upr)

exp2.avgs.filler <- exp2.clean %>%
    filter(match == "filler") %>%
    group_by(grammatical, attractor_num, att_type) %>%
    summarise(
        successes = sum(ResponseCorrect == TRUE, na.rm = TRUE),
        N = sum(!is.na(ResponseCorrect)),
        .groups = "drop"
    ) %>%
    mutate(ci_mat = purrr::pmap(
        list(successes, N),
        ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
    )) %>%
    mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
    unnest(ci_mat) %>%
    mutate(
        p_hat = successes / N,
        lwr   = lwr.ci,
        upr   = upr.ci
    ) %>%
    select(grammatical, attractor_num, att_type, successes, N, p_hat, lwr, upr)


```

```{r}
#| label: process-turklogacev2024
#| output: FALSE
source("turklogacev24.R")
```

```{r}
#| label: exp2-text-inputs

# I want accuracy, not the response yes
exp2.avgs.filler %<>%
    mutate(old.lwr = lwr, old.upr = upr) %>%
    mutate(
        p_hat = if_else(grammatical == "ungrammatical", 1 - p_hat, p_hat),
        lwr = if_else(grammatical == "ungrammatical", 1 - old.upr, old.lwr),
        upr = if_else(grammatical == "ungrammatical", 1 - old.lwr, old.upr)
    ) %>%
    select(-old.lwr, -old.upr)


exp2.nsubj <- exp2$subject %>%
    unique() %>%
    length()

exp2.nsubj.nontr <- exp2 %>%
    subset(natturk == "nat_non_turk") %>%
    .$subject %>%
    unique() %>%
    length()

exp2.nsubj.threshold <- 3

exp2.deletion <- round(100 * ((nrow(exp2.no.practice) - nrow(exp2.clean)) / nrow(exp2.no.practice)), 2)


exp2.meanage <- mean(asi(exp2.clean$age)) %>% round()
exp2.maxage <- max(asi(exp2.clean$age))
exp2.minage <- min(asi(exp2.clean$age))

# FILLER AVERAGES

exp2.avgs.filler %<>% mutate(text = paste0("M = ", round(p_hat, 2), ", CI = [", round(lwr, 2), ",", round(upr, 2), "]"))

exp2.avgs %<>% mutate(text = paste0("M = ", round(p_hat, 2), ", CI = [", round(lwr, 2), ",", round(upr, 2), "]"))


# Bind and set the desired x-axis order: rc → gen (current) → gen-tl (T&L 2024)
tl24.avgs$att_type <- "gen-tl"
all.avgs <- bind_rows(tl24.avgs, exp2.avgs) %>%
    dplyr::mutate(
        att_type = factor(att_type, levels = c("rc", "gen", "gen-tl"))
    )


```

## Participants

We recruited `r exp2.nsubj` undergraduate students to participate in the experiment in exchange for course credit. All participants were native Turkish speakers, with an average age of `r exp2.meanage` (range: `r exp2.minage` – `r exp2.maxage`). The experiment was carried out following the principles of the Declaration of Helsinki and the regulations concerning research ethics at Bogazici University. All participants provided informed consent before their participation and their identities were completely anonymised.

## Materials

We used 40 sets of sentences like (\ref{exp}), in which we manipulated (i) the number of the attractor, (ii) the type of the attractor, and (iii) the number agreement on the verb. Both plural markings were marked with the suffix -ler/-lar, while the singular number and singular agreement were marked by its absence.

```{=latex}
\begin{exe}
\ex \label{exp}
\begin{xlist}
\ex[]{\label{ss}
\gll Tut-tuğ-u aşçı mutfak-ta sürekli zıpla-dı.\\
hire-NMLZ-POSS cook[NOM] kitchen-LOC non.stop jump-PST\\
\glt `The cook they hired$_{sg}$ jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{sp}
\gll Tut-tuğ-u aşçı mutfak-ta sürekli zıpla-dı-lar.\\
hire-NMLZ-POSS cook[NOM] kitchen-LOC non.stop jump-PST-PL\\
\glt `The cook they hired$_{sg}$ jumped$_{pl}$ in the kitchen non-stop.'}
\ex[]{\label{ps}
\gll Tut-tuk-lar-ı aşçı mutfak-ta sürekli zıpla-dı.\\
hire-NMLZ-PL-POSS cook[NOM] kitchen-LOC non.stop jump-PST\\
\glt `The cook they hired$_{pl}$ jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{pp}
\gll Tut-tuk-lar-ı aşçı mutfak-ta sürekli zıpla-dı-lar.\\
hire-NMLZ-PL-POSS cook[NOM] kitchen-LOC non.stop jump-PST-PL\\
\glt `The cook they hired$_{pl}$ jumped$_{pl}$ in the kitchen non-stop.'}
\ex[]{\label{nss}
\gll Milyoner-in aşçı-sı mutfak-ta sürekli zıpla-dı.\\
millionaire-GEN cook[NOM]-POSS kitchen-LOC non.stop jump-PST\\
\glt `The millionaire's cook jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{nsp}
\gll Milyoner-in aşçı-sı mutfak-ta sürekli zıpla-dı-lar.\\
millionaire-GEN cook[NOM]-POSS kitchen-LOC non.stop jump-PST-PL\\
\glt `The millionaire's cook jumped$_{pl}$ in the kitchen non-stop.'}
\ex[]{\label{nps}
\gll Milyoner-ler-in aşçı-sı mutfak-ta sürekli zıpla-dı.\\
millionaire-PL-GEN cook[NOM]-POSS kitchen-LOC non.stop jump-PST\\
\glt `The millionaires' cook jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{npp}
\gll Milyoner-ler-in aşçı-sı mutfak-ta sürekli zıpla-dı-lar.\\
millionaire-PL-GEN cook[NOM]-POSS kitchen-LOC non.stop jump-PST-PL\\
\glt `The millionaires' cook jumped$_{pl}$ in the kitchen non-stop.'}
\end{xlist}
\end{exe}
```

All sentences were adapted by previous studies in Turkish agreement attraction [@LagoEtAl2019;@TurkLogacev2024]. Sentences with verbal attractor (\ref{ss}-\ref{pp}) started with a complex subject NP like 'tuttukları aşçı' 'the cook they hired,' in which the nominalized relative clause functioned as the attractor, and the head noun were bare. Because the plural marking on nominals is not optional and the head noun was singular, absent of -lar, in all conditions, sentences with plural verb agreement were ungrammatical. In the other 4 conditions (\ref{nss}-\ref{npp}), we simply used the items from @TurkLogacev2024, where the attractors were nominal such as 'milyonerlerin aşçısı' 'the millionaires' cook'.  To inhibit participants from forming a task-related strategy in which they deemed the sentence ungrammatical upon seeing a plural verb, half of our fillers included plural grammatical verbs, while the other half included singular ungrammatical verbs.

## Procedures

The experiment was run online, using the web-based platform Ibex Farm [@Drummond2013]. Each experimental session took approximately 25 minutes to complete. Participants provided demographic information and gave informed consent to participate in the experiment. They then proceeded to read the instructions and were given nine practice trials before the experiment began.

Each trial began with a blank screen for 600 ms, followed by a word-by-word RSVP presentation of the sentence in the center of the screen, followed by a prompt to indicate their acceptability judgment. Sentences were presented word-by-word in the center of the screen in 30 pt font size, at a rate of 400 ms per word. Participants saw a blank screen for 100 ms between each word, and to see the next item, they needed to press the space key. Participants were asked to press the key P to indicate that a sentence is acceptable and Q to indicate that the sentence is unacceptable. They were instructed to provide judgments as quickly as possible. During the practice, but not during the experiment, a warning message in red font appeared if they did not respond within 5,000 ms.

Participants saw 40 experimental and 40 filler sentences. Experimental sentences were distributed among four different lists according to a Latin-square design. Every participant saw one version of the experiment with a specific list and one item per condition.

## Analysis and Results

```{r}
#| label: exp2-models

options(mc.cores = parallel::detectCores())
theme_set(theme_bw(base_family = "Times"))


exp2.dfModel <- exp2.clean %>% subset(match != "filler")

exp2.dfModel %<>% mutate(exp = "current") %>% droplevels()
tl24.gen <- tl24.clean %>%
    subset(match != "filler") %>%
    mutate(att_type = "gen-tl") %>%
    droplevels()

exp2.all <- bind_rows(exp2.dfModel, tl24.gen)


exp2.all %<>%
    mutate(
        grammatical = factor(grammatical,
            levels = c("grammatical", "ungrammatical"),
            labels = c("Grammatical", "Ungrammatical")
        ),
        attractor_num = factor(attractor_num, # or attractor_num if that’s your column
            levels = c("singular", "plural"),
            labels = c("Singular", "Plural")
        ),
        att_type = factor(att_type, # or attractor_num if that’s your column
            levels = c("gen", "gen-tl", "rc"),
            labels = c("Gen-Current", "Gen-TL24", "RC")
        ),
    )

# Sum-code ±0.5 and give readable column names
C2 <- contr.sum(2) / 2

Cg <- C2
colnames(Cg) <- "Gram_minus_Ungram" # β > 0 ⇒ Ungram > Gram (in log-odds of YES)
Ca <- C2
colnames(Ca) <- "Plural_minus_Singular" # β > 0 ⇒ Plural > Singular (log-odds of YES)
C3 <- matrix(
    c(
        # RC vs both Gens
        -1, -1, 2, # contrast 1
        # Gen-Current vs Gen-TL24
        1, -1, 0 # contrast 2
    ),
    ncol = 2
)

# Normalize to mean-centered (sum to 0, length-scaled)
C3 <- apply(C3, 2, function(x) x / sum(abs(x)) * 2 / 3)

colnames(C3) <- c("RC_vs_Gens", "GenCurrent_vs_GenTL24")
rownames(C3) <- c("Gen-Current", "Gen-TL24", "RC")

# C3
contrasts(exp2.all$att_type) <- C3


contrasts(exp2.all$grammatical) <- Cg
contrasts(exp2.all$attractor_num) <- -Ca


make_priors_generic <- function(
    f_mean = 0, f_sd = 1,
    intercept_mean = 0.85, intercept_sd = 0.70,
    exp_rate = 1, lkj_eta = 2) {
    c(
        # Intercept
        set_prior(sprintf("normal(%g, %g)", intercept_mean, intercept_sd), class = "Intercept"),
        set_prior(sprintf("normal(%g, %g)", f_mean, f_sd), class = "b"),
        # Random-effect scales and correlations
        set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
        set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
    )
}

priors_uninformative <- make_priors_generic(
    f_mean = 0, f_sd = 1,
    exp_rate = 1,
    lkj_eta = 2
)



m.exp2.all <- brm(
    bf(ResponseCorrect ~ grammatical * attractor_num * att_type +
        (1 + grammatical * attractor_num * att_type | subject) +
        (1 + grammatical * attractor_num * att_type | item), decomp = "QR"),
    data = exp2.all,
    family = bernoulli(link = "logit"),
    prior = priors_uninformative,
    threads = threading(4),
    chains = 4, iter = 3000, warmup = 1000,
    init = 0, file = "m.exp2.all",
    seed = 1
)

m.exp2.all <- brm(
    bf(response_yes ~ grammatical * attractor_num * att_type +
        (1 + grammatical * attractor_num * att_type | subject) +
        (1 + grammatical * attractor_num * att_type | item), decomp = "QR"),
    data = exp2.all,
    family = bernoulli(link = "logit"),
    prior = priors_uninformative,
    threads = threading(4),
    chains = 4, iter = 3000, warmup = 1000,
    init = 0, file = "m.exp2.all.yes",
    seed = 1
)

```

```{r}
#| label: model-output-2

library(posterior)
library(glue)

summ_brms <- function(fit, par) {
    s <- posterior_summary(fit, pars = par)[1, ]
    c(est = unname(s["Estimate"]), l95 = unname(s["Q2.5"]), u95 = unname(s["Q97.5"]))
}
fmt <- function(x, d = 2) sprintf(paste0("%.", d, "f"), x)
trip <- function(v, d = 2) glue("{fmt(v['est'], d)} [{fmt(v['l95'], d)}, {fmt(v['u95'], d)}]")

p_gt0 <- function(fit, par) {
    sanitize_b <- function(par) paste0("", sub("b_", "", par))

    h <- hypothesis(fit, paste0(sanitize_b(par), " > 0"))
    as.numeric(h$hypothesis$Post.Prob)
}
get_col <- function(draws, name) {
    if (!name %in% names(draws)) {
        stop(sprintf("Column '%s' not found. Available: %s", name, paste(head(names(draws), 10), collapse = ", ")))
    }
    draws[[name]]
}

coef_names2 <- list(
    # main effects
    gram = "b_grammaticalGram_minus_Ungram",
    attr = "b_attractor_numPlural_minus_Singular",
    type_rc_gen = "b_att_typeRC_vs_Gens",
    type_genpair = "b_att_typeGenCurrent_vs_GenTL24",

    # two-way interactions
    gram_attr = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular",
    gram_type_rc = "b_grammaticalGram_minus_Ungram:att_typeRC_vs_Gens",
    gram_type_gen = "b_grammaticalGram_minus_Ungram:att_typeGenCurrent_vs_GenTL24",
    attr_type_rc = "b_attractor_numPlural_minus_Singular:att_typeRC_vs_Gens",
    attr_type_gen = "b_attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24",

    # three-way interactions
    way3_rc = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens",
    way3_gen = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24"
)

post_int2 <- lapply(coef_names2, \(nm) summ_brms(m.exp2.all, nm))
txt2 <- lapply(post_int2, trip)
txt_p2 <- lapply(coef_names2, \(nm) fmt(p_gt0(m.exp2.all, nm), 2))



# Extract posterior draws
draws <- as_draws_df(m.exp2.all)


# Coefficient names
b_ga_name <- "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular"
b_gat_rc_name <- "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens"
b_gat_gen_name <- "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24"

b_ga <- get_col(draws, b_ga_name)
b_gat_rc <- get_col(draws, b_gat_rc_name)
b_gat_gen <- get_col(draws, b_gat_gen_name)

# Compute effects per att_type level (Helmert-coded)
# Levels: RC_vs_Gens (+ for RC, - for both Gens); GenCurrent_vs_GenTL24 (+ for GenCurrent, - for GenTL24)
# RC: +0.5 on RC_vs_Gens, 0 on GenCurrent_vs_GenTL24
# Gen-Current: -0.25 on RC_vs_Gens, +0.5 on GenCurrent_vs_GenTL24
# Gen-TL24: -0.25 on RC_vs_Gens, -0.5 on GenCurrent_vs_GenTL24

eff_rc <- b_ga + (1/3)  * b_gat_rc + 0      * b_gat_gen
eff_gencurrent <- b_ga + (-1/6) * b_gat_rc + (1/3)  * b_gat_gen
eff_gentl24 <- b_ga + (-1/6) * b_gat_rc + (-1/3) * b_gat_gen
prob_gt0 <- function(x) mean(x > 0)


# Summarize
predicted <- tibble(
    Condition = factor(c("RC", "Gen-Current", "Gen-TL24"),
        levels = c("RC", "Gen-Current", "Gen-TL24")
    ),
    mean = c(mean(eff_rc), mean(eff_gencurrent), mean(eff_gentl24)),
    l95 = c(quantile(eff_rc, 0.025), quantile(eff_gencurrent, 0.025), quantile(eff_gentl24, 0.025)),
    u95 = c(quantile(eff_rc, 0.975), quantile(eff_gencurrent, 0.975), quantile(eff_gentl24, 0.975)),
    P_gt0 = c(prob_gt0(eff_rc), prob_gt0(eff_gencurrent), prob_gt0(eff_gentl24)),
    P_lt0 = c(1 - prob_gt0(eff_rc), 1 - prob_gt0(eff_gencurrent), 1 - prob_gt0(eff_gentl24))
)

predicted <- predicted %>%
    mutate(
        # format p values: "<0.01", ">0.99", or rounded
        p_formatted = case_when(
            P_lt0 < 0.01 ~ "<0.01",
            P_lt0 > 0.99 ~ ">0.99",
            TRUE ~ paste0("=", sprintf("%.2f", round(P_lt0, 2)))
        ),

        # compose text string
        text = paste0(
            "M = ", round(mean, 2),
            ", CI = [", round(l95, 2), ", ", round(u95, 2), "]",
            ", P(<0) ", p_formatted
        )
    )


h <- hypothesis(
    m.exp2.all,
    c(
        # RC
        "(1*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular
      + (1/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens
      + 0*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0",
        # Gen-Current
        "(1*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular
      + (-1/6)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens
      + (1/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0",
        # Gen-TL24
        "(1*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular
      + (-1/6)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeRC_vs_Gens
      + (-1/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0",
        # GenCurrent − GenTL24 difference
        "((2/3)*grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular:att_typeGenCurrent_vs_GenTL24) < 0"
    )
)

exp2_atts <- as_tibble(h$hypothesis) %>%
    transmute(
        contrast = c("RC", "Gen-Current", "Gen-TL24", "GenCurrent − GenTL24"),
        mean = Estimate, l95 = CI.Lower, u95 = CI.Upper,
        prob_lt0 = Post.Prob,
        text = paste0(
            "M = ", round(mean, 2),
            ", CI = [", round(l95, 2), ", ", round(u95, 2), "]",
            ", P(<0) = ",
            ifelse(is.na(prob_lt0), "NA",
                ifelse(prob_lt0 < 0.01, "<0.01",
                    ifelse(prob_lt0 > 0.99, ">0.99", round(prob_lt0, 2))
                )
            )
        )
    )

predicted <- exp2_atts %>%
    filter(contrast %in% c("RC", "Gen-Current", "Gen-TL24")) %>%
    transmute(
        Condition = recode(
            contrast,
            "RC" = "Attraction: Verbal\n(Current)",
            "Gen-Current" = "Attraction: Nominal\n(Current)",
            "Gen-TL24" = "Attraction: Nominal\n(Türk & Logačev 2024)"
        ),
        mean, l95, u95
    )

## 2) Pull the overall acceptability difference (Gen-Current vs Gen-TL24) from the model
fix <- posterior_summary(m.exp2.all, pars = "^b_") %>%
    as_tibble(rownames = "term")

# main effect of att_type GenCurrent_vs_GenTL24
genpair_row <- fix %>%
    filter(str_detect(term, "^b_att_type.*GenCurrent_vs_GenTL24$")) %>%
    slice(1)

coef_name <- genpair_row$term
# If this is empty, run: rownames(fixef(m.exp2.all)) and copy the exact name.

# 2) Compute P(<0) from draws
dr <- as_draws_df(m.exp2.all)
stopifnot(coef_name %in% names(dr))
prob_lt0 <- mean(dr[[coef_name]] < 0)

# 3) Build overall_df with prob and text
overall_df <- tibble(
    Condition = "Overall Acceptability:\nGen-Current − Gen-TL24",
    mean = genpair_row$Estimate,
    l95 = genpair_row$Q2.5,
    u95 = genpair_row$Q97.5,
)

## 3) Gen vs Gen difference in *attraction* from your exp2_atts (row 4)
diff_attr_df <- exp2_atts %>%
    filter(contrast == "GenCurrent − GenTL24") %>%
    transmute(
        Condition = "Attraction Difference:\nGen-Current − Gen-TL24",
        mean, l95, u95
    )

predicted_between <- bind_rows(diff_attr_df, overall_df, predicted)

overall_df <- overall_df %>%
    mutate(prob_lt0 = prob_lt0) %>%
    mutate(
        text = paste0(
            "M = ", round(mean, 2),
            ", CI = [", round(l95, 2), ", ", round(u95, 2), "]",
            ", P(<0) = ",
            ifelse(is.na(prob_lt0), "NA",
                ifelse(prob_lt0 < 0.01, "<0.01",
                    ifelse(prob_lt0 > 0.99, ">0.99", round(prob_lt0, 2))
                )
            )
        )
    )

predicted_between <- predicted_between %>%
    mutate(
        Condition = factor(
            Condition,
            levels = rev(c(
                "Attraction: Verbal\n(Current)", # A in RC
                "Attraction: Nominal\n(Current)", # A in Gen-Current
                "Attraction: Nominal\n(Türk & Logačev 2024)", # A in TL24
                "Attraction Difference:\nGen-Current − Gen-TL24", # Diff between Gens
                "Overall Acceptability:\nGen-Current − Gen-TL24" # Overall acceptability
            ))
        )
    )

p_between <- ggplot(predicted_between, aes(y = Condition, x = mean)) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray60") +
    geom_point(size = 3) +
    geom_errorbarh(aes(xmin = l95, xmax = u95), height = 0.15, linewidth = 0.7) +
    xlab(expression(paste("Effect Size (", beta, ")"))) +
    ylab(NULL) +
    theme_minimal(base_family = "Times") +
    theme(
        axis.text.y = element_text(size = 8),
        axis.text.x = element_text(size = 8),
        axis.title.x = element_text(size = 8),
        panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank()
    )

```


Participants showed high accuracy in both grammatical (`r get_value(exp2.avgs.filler, text, grammatical == "grammatical")`) and ungrammatical filler sentences (`r get_value(exp2.avgs.filler, text, grammatical == "ungrammatical")`), indicating that they understood the task and performed it reliably.

@fig-exp2-condition-means presents the overall means and credible intervals for 'yes' responses across experimental conditions, as well as the previous data from @TurkLogacev2024, which is quite similar to the magnitude of @LagoEtAl2019. As shown, in our study, participant gave more 'yes' responses to ungrammatical sentences with plural genitive-marked nominal attractors (`r get_value(all.avgs, text, grammatical == "ungrammatical", attractor_num == "plural", att_type == "gen")`) compared to their singular counterparts (`r get_value(all.avgs, text, grammatical == "ungrammatical", attractor_num == "plural", att_type == "gen")`).

However, similar increase in acceptability was not found with relative clause attractors (M = `r get_value(all.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "singular", att_type == "rc")` and `r get_value(all.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "plural", att_type == "rc")`, CI = [`r get_value(all.avgs, lwr, grammatical == "ungrammatical", attractor_num == "singular", att_type == "rc")`, `r get_value(all.avgs, upr, grammatical == "ungrammatical", attractor_num == "singular", att_type == "rc")`] and [`r get_value(all.avgs, lwr, grammatical == "ungrammatical", attractor_num == "plural", att_type == "rc")`, `r get_value(all.avgs, upr, grammatical == "ungrammatical", attractor_num == "plural", att_type == "rc")`] for singular and plural attractors, respectively). Participants rated grammatical sentences similarly independent of the attractor number or attractor type.

```{r}
#| label: fig-exp2-condition-means
#| fig-cap: "Mean proportion of 'acceptable' responses by grammaticality, attractor number and attractor type. Error bars show 95% Clopper–Pearson confidence intervals. "
#| fig-width: 6
#| fig-height: 3

exp2.gram.label <- c(
    "grammatical"   = "Grammatical\n(Singular Verb)",
    "ungrammatical" = "Ungrammatical\n(Plural Verb)"
)
exp2.att_type.label <- c(
    "rc"     = "Verbal\n(Current Paper)",
    "gen"    = "Nominal\n(Current Paper)",
    "gen-tl" = "Nominal\n(TL2024)"
)

# Plot: X = Attractor Type (ordered & labeled), facet = Grammaticality
all.avgs %>%
    ggplot(aes(
        x = att_type, y = p_hat,
        linetype = attractor_num, group = attractor_num
    )) +
    geom_point(position = position_dodge(0.3)) +
    # geom_line() +
    geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0, position = position_dodge(0.3)) +
    facet_wrap(~grammatical, labeller = as_labeller(exp2.gram.label)) +
    scale_x_discrete(labels = exp2.att_type.label, drop = FALSE) +
    xlab("Attractor Type") +
    ylab("Percentage 'acceptable'") +
    scale_y_continuous(labels = scales::percent) +
    scale_linetype_discrete(
        name = "Attractor Number",
        labels = c("Singular", "Plural")
    ) +
    theme_minimal(base_family = "Times") +
    theme(
        legend.position = "bottom",
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(size = 9),
        axis.text.y = element_text(size = 9),
        axis.text.x = element_text(size = 9),
        axis.title.x = element_text(size = 9),
    )
```

Our models also showed similar results, assuming a Bernoulli logit link. Our main research question was whether verbal attractors induced attraction effects. We also wanted to verify the cannonical attraction effects in Turkish with nominal attractors.  To that end, we included genitive marked nominals from data from our experiment and @TurkLogacev2024. The model was fitted to the binary *yes/no* responses and assumed uninformative priors. Grammaticality and Attractor Number was sum coded (grammatical = 0.5, ungrammatical = −0.5; plural = 0.5, singular = −0.5). Attractor Type (Nominal-Current, Nominal-TL24, Verbal) was represented by two orthogonal Helmert contrasts: an initial contrast comparing verbal attractors to the average of the two nominal conditions (Nominal-Current = −1/6, Nominal-TL24 = −1/6, Verbal = 1/3) and another contrast comparing the two nominal conditions (Nominal-Current = 1/3, Nominal-TL24 = −1/3, Verbal = 0). All fixed effects and their interaction were included, along with random intercepts and slopes for both subjects and items. 

We present posterior summaries of estimated regression effects from our model in @fig-exp2-fixed-effects.  Our model showed a robust attraction in both nominal attractor cases, with strongly negative effects for our nominal items (`r get_value(exp2_atts, text, contrast == "Gen-Current")`) and items from @TurkLogacev2024 (`r get_value(exp2_atts, text, contrast == "Gen-TL24")`).  More importantly, our model found no evidence for an attraction in verbal attractor conditions (`r get_value(exp2_atts, text, contrast == "RC")`), verifying our observations in the descriptive statistics.  We did not find an evidence for a difference in magnitude of attraction between the two nominal-type attractors was not found (`r get_value(exp2_atts, text, contrast == "GenCurrent − GenTL24")`), suggesting the presence of an additional conditions did not affect attraction magnitudes.  Finally, we found strong evidence for a decreased overall acceptability for nominal items in our experiment (`r get_value(overall_df, text)`), suggesting the within-experimental distribution did affect overall acceptability, but not attraction.

```{r}
#| label: fig-exp2-fixed-effects
#| fig-cap: "Posterior summaries of attraction-related effects. Points indicate posterior means, and horizontal bars show 95% credible intervals on the log-odds (β) scale. Attraction was estimated as the interaction between grammaticality and attractor number within each attractor type. Negative values indicate stronger attraction (a reduced ungrammaticality penalty in plural-attractor conditions). Dashed line denotes zero (no effect)."
#| fig-width: 6
#| fig-height: 2

p_between
```

## Discussion

In Experiment 1, we tested whether phonological overlap between nominal and verbal plural morphemes in Turkish induces agreement attraction. The results provided no evidence for attraction driven by surface-form similarity. Ungrammatical sentences with plural-marked verbs were not judged more acceptable when the relative clause verb contained a plural morpheme. Instead, participants reliably rejected such sentences regardless of attractor number while showing a canonical attraction effects with nominal attractors. This indicates that the verbal plural marker *-lAr* does not create the same type of interference observed with nominal plural attractors.

<!-- the reason we did not find attraction effects in Experiment 1 was due to the lack of attraction-inducing conditions.  Our results showed that attraction effects in verbal attractor condition, purely phonological overlap, did not surface even when there are robust attraction-inducing trials.  Participants reliably rejected ungrammatical sentences with verbal attractors regardless of attractor number. -->

Our results and between experiment comparison showed that within-experiment statistics, i.e. exposure to verbal attraction conditions attraction items, did not substantially reduced the magnitude of the attraction effects.  However, the overall acceptability in our nominal attractor sentences were reduced compared to the trials from @TurkLogacev2024.  This is inline with previous findings that shows participants' judgments within the experiment are modulated by the distribution of trials.  Interestingly, previous studies achieved this with instructions or filler elements [@HammerlyEtAl2019; @ArehalliWittenberg2021].  We show that the experimental conditions and the presence of an effect within a subset of conditions also plays a role in modulating overall acceptability.

One remaining concern is that our mixed design, which combined canonical nominal attractor items with purely phonological verbal attractor items, might itself have shaped the pattern of responses. The presence of robust nominal attraction trials could have led participants to adjust their expectations about agreement violations or to adopt task strategies that obscure any weaker effect of verbal plural markers [@HammerlyEtAl2022; @Turk2022]. To assess whether the absence of verbal attraction in Experiment 1 reflects a genuine lack of interference from verbal -lAr rather than an artifact of the item distribution, Experiment 2 replicated the verbal attractor conditions while removing all nominal attractor items. This design allows us to test whether the null effect for verbal -lAr persists when verbal plural morphology is the only potential attractor in the experiment.


# Experiment 2: Replication

```{r}
#| label: exp1-data-prep

exp1 <- read_experimental_data("../data/results.txt", subj_offset = 2000, item_offset = 2000)

exp1 %<>% mutate(exp_condition = case_when(
  exp_condition == "filler" & item_num <= 120 ~ "filler_ung",
  exp_condition == "filler" & item_num >= 121 ~ "filler_g",
  exp_condition == "practice" ~ "practice",
  exp_condition == "condition_b" ~ "condition_b",
  exp_condition == "condition_a" ~ "condition_a",
  exp_condition == "condition_c" ~ "condition_c",
  exp_condition == "condition_d" ~ "condition_d"
))


exp1.conditions <- data.frame(
  exp_condition = c("practice", "condition_a", "condition_b", "condition_c", "condition_d", "filler_ung", "filler_g"),
  experiment =    c("practice", "AgrAttr",     "AgrAttr",     "AgrAttr",     "AgrAttr",     "filler",     "filler"),
  condition =     c("practice", "a",           "b",           "c",           "d",           "filler_ung", "filler_g"),
  grammatical =   c("practice", "ungram",      "gram",        "ungram",      "gram",        "ungram",     "gram"),
  verb_num =      c("practice", "pl",          "sg",          "pl",          "sg",          "sg",         "pl"),
  attractor_num = c("practice", "pl",          "pl",          "sg",          "sg",          'filler',     'filler'),
  match =         c("practice", "mismatch",    "mismatch",    "match",       "match",       'filler',     'filler'),
  stringsAsFactors = T
)

exp1 %<>% left_join(exp1.conditions, by = "exp_condition")

exp1.no.practice <- exp1 %>% subset(exp_condition != "practice")

# accuracy: 0.25
# rt_below: 200
# rt_upper: 4999
exp1.clean <- exclude_bad_subjects(
  exp1,
  accuracy_threshold = 0.25,
  rt_below = 200,
  rt_upper = 4999
)

exp1.clean %<>% no_null_no_practice(.)

stopifnot(exp1.clean %>% subset(is.na(response_yes)) %>% nrow() == 0)

# DIFF DATA =====
exp1.diff <- dplyr::anti_join(exp1, exp1.clean) %>%
  filter(exp_condition != "practice")

exp1.clean$isGram <- ifelse(exp1.clean$grammatical == "ungram", F, T)
exp1.clean$p_acc <- with(exp1.clean, response_yes & isGram)
exp1.clean %<>% mutate(ResponseCorrect = (response_yes == (grammatical == "gram")))

# Merge

exp1.clean %<>% ungroup() %>%
                      dplyr::select(source=experiment,
                                    grammatical,
                                    attractor_num,
                                    match,
                                    age,
                                    # condition,
                                    subject,
                                    trial_no,
                                    item,
                                    response_yes,
                                    RT,
                                    ResponseCorrect)
exp1.clean$experiment <- "Experiment 1"
exp1.clean$grammatical %<>% dplyr::recode(gram="grammatical", ungram="ungrammatical")
exp1.clean$attractor_num %<>% dplyr::recode(pl="plural", sg="singular")
exp1.clean$item %<>% as.factor()
exp1.clean$subject %<>% as.character()

```

```{r}
#| label: exp1-avgs

exp1.avgs <- exp1.clean %>%
  filter(match != "filler") %>%
  group_by(grammatical, attractor_num, match) %>%
  summarise(
    successes = sum(ResponseCorrect == TRUE, na.rm = TRUE),
    N         = sum(!is.na(ResponseCorrect)),
    .groups = "drop"
  ) %>%
  mutate(ci_mat = purrr::pmap(
    list(successes, N),
    ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
  )) %>%
  mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
  unnest(ci_mat) %>%
  mutate(
    p_hat = successes / N,
    lwr   = lwr.ci,
    upr   = upr.ci
  ) %>%
  select(grammatical, attractor_num, match, successes, N, p_hat, lwr, upr)

exp1.avgs.filler <- exp1.clean %>%
  filter(match == "filler") %>%
  group_by(grammatical, attractor_num, match) %>%
  summarise(
    successes = sum(ResponseCorrect == TRUE, na.rm = TRUE),
    N         = sum(!is.na(ResponseCorrect)),
    .groups = "drop"
  ) %>%
  mutate(ci_mat = purrr::pmap(
    list(successes, N),
    ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
  )) %>%
  mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
  unnest(ci_mat) %>%
  mutate(
    p_hat = successes / N,
    lwr   = lwr.ci,
    upr   = upr.ci
  ) %>%
  select(grammatical, attractor_num, match, successes, N, p_hat, lwr, upr)


```

```{r}
#| label: exp1-text-inputs

# I want accuracy, not the response yes
exp1.avgs.filler %<>%
  mutate(old.lwr = lwr, old.upr = upr) %>%
  mutate(
  p_hat = if_else(grammatical == "ungrammatical", 1 - p_hat, p_hat),
  lwr = if_else(grammatical == "ungrammatical", 1 - old.upr, old.lwr),
  upr = if_else(grammatical == "ungrammatical", 1 - old.lwr, old.upr))  %>%
  select(-old.lwr, -old.upr)


exp1.nsubj <- exp1$subject %>% unique() %>% length()

exp1.nsubj.nontr <- exp1 %>%
  subset(natturk == "nat_non_turk") %>%
  .$subject %>%
  unique() %>%
  length()

exp1.nsubj.threshold <- 2

exp1.deletion <- round(100*((nrow(exp1.no.practice)-nrow(exp1.clean))  / nrow(exp1.no.practice)),2)


exp1.meanage <- mean(asi(exp1.clean$age)) %>% round()
exp1.maxage <- max(asi(exp1.clean$age))
exp1.minage <- min(asi(exp1.clean$age))

# FILLER AVERAGES

exp1.avgs.filler %<>% mutate(text = paste0("M = ", round(p_hat,2), ", CI = [", round(lwr,2) , ",", round(upr,2) ,"]"))

exp1.avgs %<>% mutate(text = paste0("M = ", round(p_hat,2), ", CI = [", round(lwr,2) , ",", round(upr,2) ,"]"))

```

## Participants

We recruited `r exp1.nsubj` undergraduate students to participate in the experiment in exchange for course credit. All participants were native Turkish speakers, with an average age of `r exp1.meanage` (range: `r exp1.minage` – `r exp1.maxage`). The experiment was carried out following the principles of the Declaration of Helsinki and the regulations concerning research ethics at Bogazici University. All participants provided informed consent before their participation and their identities were completely anonymised.

## Materials and Procedure

Experiment 2 used only the verbal attractor conditions from Experiment 1. The procedure was identical to that of Experiment 1.

## Analysis and Results

```{r}
#| label: exp1-models

options(mc.cores = parallel::detectCores())
theme_set(theme_bw(base_family = "Times"))


exp1.dfModel <- exp1.clean %>% subset(match != "filler")


exp1.dfModel %<>%
    mutate(
        grammatical = factor(grammatical,
            levels = c("grammatical", "ungrammatical"),
            labels = c("Grammatical", "Ungrammatical")
        ),
        attractor_num = factor(attractor_num, # or attractor_num if that’s your column
            levels = c("singular", "plural"),
            labels = c("Singular", "Plural")
        )
    )

# Sum-code ±0.5 and give readable column names
C2 <- contr.sum(2) / 2

Cg <- C2
colnames(Cg) <- "Gram_minus_Ungram" # β > 0 ⇒ Ungram > Gram (in log-odds of YES)
Ca <- C2
colnames(Ca) <- "Plural_minus_Singular" # β > 0 ⇒ Plural > Singular (log-odds of YES)

contrasts(exp1.dfModel$grammatical) <- Cg
contrasts(exp1.dfModel$attractor_num) <- -Ca


make_priors <- function(
    inter_ga_mean = 0.0, inter_ga_sd = 0.10, # Gram × Attr (classic attraction term)
    main_g_mean = 1.0, main_g_sd = 0.50, # Grammaticality main effect (your previous spec)
    main_a_mean = 0.30, main_a_sd = 0.40, # Attractor Number main effect
    intercept_mean = 0.85, intercept_sd = 0.70,
    exp_rate = 1, lkj_eta = 2) {
    c(
        # Intercept
        set_prior(sprintf("normal(%g, %g)", intercept_mean, intercept_sd), class = "Intercept"),

        # Main effects
        set_prior(sprintf("normal(%g, %g)", main_g_mean, main_g_sd),
            class = "b", coef = "grammaticalGram_minus_Ungram"
        ),
        set_prior(sprintf("normal(%g, %g)", main_a_mean, main_a_sd),
            class = "b", coef = "attractor_numPlural_minus_Singular"
        ),
        # Two-way interactions
        set_prior(sprintf("normal(%g, %g)", inter_ga_mean, inter_ga_sd),
            class = "b", coef = "grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular"
        ),
        # Random-effect scales and correlations
        set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
        set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
    )
}

priors_uninformative <- make_priors(
    inter_ga_mean   = 0, inter_ga_sd   = 1,
    main_g_mean     = 0, main_g_sd     = 1,
    main_a_mean     = 0, main_a_sd     = 1,
    intercept_mean  = 0, intercept_sd  = 1,
    exp_rate        = 1,
    lkj_eta         = 2
)


m.exp1 <- brm(
    response_yes ~ grammatical * attractor_num +
        (1 + grammatical * attractor_num | subject) +
        (1 + grammatical * attractor_num | item),
    data = exp1.dfModel,
    family = bernoulli(link = "logit"),
    prior = priors_uninformative,
    sample_prior = "yes", file = "m.exp1",
    save_pars = save_pars(all = TRUE),
    chains = 4, iter = 10000, warmup = 2500, seed = 1
)



```

```{r}
#| label: model-output


library(posterior)
library(glue)

# --- helpers ---
coef_names <- list(
    gram  = "b_grammaticalGram_minus_Ungram",
    attr  = "b_attractor_numPlural_minus_Singular",
    inter = "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular"
)

post_int <- list(
    gram  = summ_brms(m.exp1, coef_names$gram),
    attr  = summ_brms(m.exp1, coef_names$attr),
    inter = summ_brms(m.exp1, coef_names$inter)
)
txt <- list(
    gram  = trip(post_int$gram),
    attr  = trip(post_int$attr),
    inter = trip(post_int$inter)
)


txt_p <- list(
    gram  = fmt(p_gt0(m.exp1, coef_names$gram), 2),
    attr  = fmt(p_gt0(m.exp1, coef_names$attr), 2),
    inter = fmt(p_gt0(m.exp1, coef_names$inter), 2)
)

```

```{r}
#| label: nested-models


grammaticals <- exp1.dfModel %>% filter(grammatical == "Grammatical")

ungrammaticals <- exp1.dfModel %>% filter(grammatical == "Ungrammatical")

make_priors_g <- function(inter_mean = 0.4, inter_sd = 0.1,
                        exp_rate = 1, lkj_eta = 2) {
    c(
        set_prior("normal(0.85, 0.7)", class = "Intercept"),
        set_prior("normal(0.30, 0.40)",
            class = "b",
            coef = "attractor_numPlural_minus_Singular"
        ),
        set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
        set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
    )
}

m.exp1.g <- brm(
    response_yes ~ attractor_num +
        (1 + attractor_num | subject) +
        (1 + attractor_num | item),
    data = grammaticals,
    family = bernoulli(link = "logit"),
    prior = make_priors_g(),
    sample_prior = "yes", file = "m.exp1.g",
    save_pars = save_pars(all = TRUE),
    chains = 4, iter = 4000, warmup = 2000, seed = 1
)


m.exp1.u <- brm(
    response_yes ~ attractor_num +
        (1 + attractor_num | subject) +
        (1 + attractor_num | item),
    data = ungrammaticals,
    family = bernoulli(link = "logit"),
    prior = make_priors_g(),
    sample_prior = "yes", file = "m.exp1.u",
    save_pars = save_pars(all = TRUE),
    chains = 4, iter = 4000, warmup = 2000, seed = 1
)

post_int_g <- list(
    attr_g  = summ_brms(m.exp1.g, coef_names$attr),
    attr_u  = summ_brms(m.exp1.u, coef_names$attr)
)

txt_g <- list(
    attr_g = trip(post_int_g$attr_g),
    attr_u = trip(post_int_g$attr_u)
)

txt_g_p <- list(
    attr_g = fmt(p_gt0(m.exp1.g, coef_names$attr), 2),
    attr_u = fmt(p_gt0(m.exp1.u, coef_names$attr), 2)
)



```

Participants showed high accuracy in both grammatical (`r get_value(exp1.avgs.filler, text, grammatical == "grammatical")`) and ungrammatical filler sentences (`r get_value(exp1.avgs.filler, text, grammatical == "ungrammatical")`), indicating that they understood the task and performed it reliably.

@fig-exp1-condition-means presents the overall means and credible intervals for 'yes' responses across experimental conditions. As shown, ungrammatical sentences with plural attractors were rated as acceptable as their counterparts with singular attractors (M = `r get_value(exp1.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "singular")` and `r get_value(exp1.avgs, p_hat, grammatical == "ungrammatical", attractor_num == "plural")`, CI = [`r get_value(exp1.avgs, lwr, grammatical == "ungrammatical", attractor_num == "singular")`, `r get_value(exp1.avgs, upr, grammatical == "ungrammatical", attractor_num == "singular")`] and [`r get_value(exp1.avgs, lwr, grammatical == "ungrammatical", attractor_num == "plural")`, `r get_value(exp1.avgs, upr, grammatical == "ungrammatical", attractor_num == "plural")`] for singular and plural attractors, respectively).

On the other hand, accuracy in grammatical conditions was modulated by the number of the attractor in an unexpected way. Participants rated grammatical sentences with singular attractors as grammatical less often (`r get_value(exp1.avgs, text, grammatical == "grammatical", attractor_num == "singular")`) compared to their counterpars with plural attractors (`r get_value(exp1.avgs, text, grammatical == "grammatical", attractor_num == "plural")`).

```{r}
#| label: fig-exp1-condition-means
#| fig-cap: "Mean proportion of 'acceptable' responses by grammaticality and attractor number. Error bars show 95% Clopper–Pearson confidence intervals. "
#| fig-width: 6
#| fig-height: 3.5

exp1.gram.label <- c(
    grammatical = "Grammatical\n(Singular Verb)",
    ungrammatical = "Ungrammatical\n(Plural Verb)"
)

# responses

exp1.avgs %>%
    ggplot(aes(grammatical, p_hat,
        linetype = attractor_num,
        group = attractor_num
    )) +
    geom_point(position = position_dodge(0.3)) +
    # geom_line() +
    geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0, position = position_dodge(0.3)) +
    theme(strip.background = element_rect(fill = "white")) +
    xlab("Grammaticality") +
    ylab("Percentage Correct") +
    scale_y_continuous(labels = scales::percent) +
    scale_linetype_discrete(
        name = "Attractor Number",
        labels = c("Plural", "Singular")
    ) +
    scale_x_discrete(labels = exp1.gram.label) +
    theme_minimal(base_family = "Times") +
    theme(legend.position = "bottom")

```

These descriptive trends were confirmed by our Bayesian mixed-effects models implemented in brms,  assuming a Bernoulli logit link. The model was fitted to the binary *yes/no* responses and included fixed effects for Grammaticality and Attractor Number and their interaction, and random intercepts and slopes for both subjects and items.

Posterior estimates are summarized in @fig-exp1-fixed-effects. The model revealed a positive effect of grammaticality ($\beta$ = `r txt$gram`, P($\beta$ > `r txt_p$gram`)), but no reliable main effect of attractor number ($\beta$ = `r txt$attr`, P($\beta$ > `r txt_p$attr`)). On the other hand, there was a small but positive interaction ($\beta$ = `r txt$inter`, P($\beta$ > `r txt_p$inter`)). To clarify the effects' presence in grammaticals only, we fitted two more models that is fitted to the subset of the data. While the model fitted to grammatical conditions only showed an effect of attractor number ($\beta$ = `r txt_g$attr_g`, P($\beta$ > `r txt_g_p$attr_g`)), the model fitted to ungrammatical conditions, attraction relevant conditions, did not provide evidence for the effect of number manipulation ($\beta$ = `r txt_g$attr_u`, P($\beta$ > `r txt_g_p$attr_g`)). These results suggest that the presence of a plural attractor did not increase the acceptability of ungrammatical sentences, nor was this relationship modulated by grammaticality.

```{r}
#| label: fig-exp1-fixed-effects
#| fig-cap: "Posterior means and 95% credible intervals for fixed effects in the two Bayesian models. The x-axis shows the posterior mean (log-odds scale). The blue intervals correspond to the model in which a positive interaction was assumed, and the orange intervals to the model in which it was not. "
#| fig-width: 6
#| fig-height: 2

fixef_whiskers <- function(fit, label) {
    posterior_summary(fit, pars = "^b_") %>%
        as_tibble(rownames = "term") %>%
        filter(term != "b_Intercept") %>%
        transmute(
            term,
            est = Estimate,
            l95 = Q2.5,
            u95 = Q97.5,
            model = label
        )
}

lab_no_int <- "Not assumed\nN(0,0.25)"
lab_int <- "Assumed\nN(0.4,0.25)"

df_plot <- bind_rows(
    fixef_whiskers(m.exp1, "Uninformative")
) %>%
    mutate(
        term_clean = case_when(
            term == "b_grammaticalGram_minus_Ungram" ~ "Grammaticality",
            term == "b_attractor_numPlural_minus_Singular" ~ "Attractor",
            term == "b_grammaticalGram_minus_Ungram:attractor_numPlural_minus_Singular" ~ "Interaction",
            TRUE ~ term
        ),
        term_clean = factor(term_clean,
            levels = rev(c("Grammaticality", "Attractor", "Interaction"))
        )
    )

ggplot(df_plot, aes(x = est, y = term_clean)) +
    geom_vline(xintercept = 0, linetype = 3) +
    geom_errorbarh(aes(xmin = l95, xmax = u95),
        position = position_dodge(width = 0.5), height = 0.2
    ) +
    geom_point(position = position_dodge(width = 0.5), size = 2.4) +
    labs(
        x = "Posterior (log-odds)",
        y = NULL,
        color = "Interaction",
    ) +
    theme_minimal(base_size = 10, base_family = "Times") +
    theme(panel.grid.minor = element_blank())

```

## Discussion

Experiment 2 replicated the verbal attractor conditions from Experiment 1 in isolation and again revealed no evidence for agreement attraction driven by verbal plural markers. Ungrammatical sentences with plural marked main verbs were rejected at similar rates regardless of whether the reduced clause verb bore plural *-lAr* or not, and there were no reliable effects of attractor number or interactions involving attractor number. This confirms that the absence of a verbal attraction effect in Experiment 1 was not due to the presence of nominal attractor items or to within experiment item statistics. 

Unexpectedly, grammatical sentences with singular attractors were judged less acceptable than those with plural attractors. This effect is unlikely to reflect agreement attraction, since it arises in the opposite direction. One possibility is that it results from an interaction between plausibility and referential availability. The plural morpheme can license a more general interpretation by allowing an unspecific reference, whereas the singular reduced relative clause more strongly invites a specific referent, which may be less accessible in the context of the task. We do not pursue this explanation further, as it falls outside the scope of the present paper.


<!-- One possible reason for the absence of attraction may lie in the within-experiment statistics. Previous work has shown that participants' global expectations about the frequency of grammatical and ungrammatical sentences can alter attraction patterns. @HammerlyEtAl2019 and @Turk2022 demonstrated that reducing the proportion of grammatical trials led to attraction effects even in otherwise grammatical sentences. Similarly, @ArehalliWittenberg2021 reported that filler distribution affects error correction rates. It is possible that the current experiment’s distribution discouraged attraction: if participants rarely encountered conditions that supported attraction, they may have maintained a strong bias against plural-marked verbs, reinforcing this bias throughout the session. -->

<!-- To test this possibility, Experiment 2 introduced additional conditions that have previously been shown to elicit attraction in Turkish \citep{TurkLogacev2024, LagoEtAl2019}. This allowed us to assess whether the inclusion of genuine nominal attractors modulates the likelihood of errors and whether participants adapt to the statistical environment of the task. -->

# General Discussion

In two high-powered speeded acceptability judgment experiments, we tested whether pure phonological overlap between agreement morphemes can elicit agreement attraction. Our goal was to evaluate previous accounts that attribute attraction to accidental or non-accidental syncretism between forms that can serve as agreement controllers. Turkish provides a useful test case because the plural suffix -lAr appears both on verbs and on nouns, but only nominal -lAr can control agreement. If phonological overlap alone can activate controller-relevant cues, then plural-marked verbs embedded in reduced relative clauses should induce attraction effects even though they cannot syntactically control agreement.

Across both experiments, we found that Turkish attraction is determined by being a potential controller rather than merely resembling one. Participants did not produce or endorse attraction errors in sentences containing verbal attractors, and this absence of attraction persisted even when the same participants showed robust attraction with nominal attractors in the same session.

These results indicate that attraction depends on abstract feature overlap with potential controllers, not on surface-form similarity. This pattern converges with prior results in English and Turkish that failed to find attraction for pseudoplural or phonologically plural forms [@BockEberhard1993; @HaskellMacDonald2003; @NicolEtAl:2016], and stands in contrast to findings from Russian [@Slioussar2018].

In @Slioussar2018, genitive-marked singular nouns that were homophonous with nominative plurals elicited greater attraction effects than their genitive-plural counterparts. This is striking because the relevant nouns lacked a plural feature that could percolate or serve as a retrieval cue. The effect was therefore interpreted as evidence that comprehenders can use phonological form to activate abstract agreement features. However, it is important to note that the evidence for phonological attraction in Russian rests on a small empirical base. The production and comprehension experiments in [@Slioussar2018] included only 32 participants each, and the attraction effects were derived from a small number of error trials (13 in production and 18 in comprehension). Given the low number of critical observations, such effects are vulnerable to sampling variability and may not generalize beyond that dataset.

The high-powered Turkish results challenge that interpretation. Despite identical surface overlap between verbal and nominal plural morphology, phonological similarity alone did not yield attraction. This cross-linguistic contrast suggests that form-based activation of agreement features is not a universal property of the parsing system but, at best, depends on language-specific mappings between morphology and syntactic function [@DillonKeshev2024].

A more plausible account is that attraction is modulated by the availability of morphosyntactic features that can signal controllerhood. Syncretism contributes to attraction only when one of the syncretic forms can legitimately control agreement or share features with the target. In other words, it is not form overlap per se, but feature ambiguity that matters. This interpretation aligns with cross-linguistic findings showing that attraction is strongest when the attractor bears case or number morphology that is sometimes associated with subjects or agreement controllers [@LagoEtAl2019; @BhatiaDillon2022; @BleotuDillon2024; @HartsuikerEtAl2003]. Earlier formulations of these models left open whether 'looking like' a controller or 'being able to be' a controller was critical. The present results favor the latter: only morphologically licensed controllers engage in attraction.

# References {.unnumbered}

\newcommand{\doi}[1]{\href{http://dx.doi.org/#1}{http://dx.doi.org/#1}}
\begingroup
\raggedright
\singlespacing
::: {#refs}
:::
\endgroup
