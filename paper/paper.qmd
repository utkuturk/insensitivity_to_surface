---
title: "Sensitivity to within-experiment statistics: A case from Turkish agreement attraction"
subtitle: "Within-experiment statistics in agreement attraction"
author:
  - name: Utku Turk
    email: utkuturk@umd.edu
    affiliations: 
        - id: umd
          name: University of Maryland, College Park
          department: Linguistics
          address: Marie Mount Hall
          city: College Park
          state: MD
          postal-code: 20742
    attributes:
        corresponding: true
    # note: This is the first author footnote.
abstract: |
  Surface level does not affect it, but within-experiment statistics effect the findings.
keywords: 
  - keyword1
  - keyword2
date: last-modified
bibliography: bibliography.bib
format:
  elsevier-pdf:
    include-in-header:
      - preamble.tex
    keep-tex: true
    # latex-clean: false
    # latex-min-runs: 3
    journal:
      name: Cognition
      formatting: preprint
      # model: 5p # Don't set a model with preprint
      cite-style: authoryear
filters:
  - wordcount
execute:
  echo: false
  message: false
  warning: false
---


```{r setup}
set.seed(01110011)

library(tidyverse)
library(brms)
library(data.table)
library(gdata)
library(magrittr)
library(DescTools)
select <- dplyr::select
```


```{r functions}
read_experimental_data <- function(fname, subj_offset = 0, item_offset = 0, verbose = F)
{
  data <- read.csv(fname, 
                   header = F, 
                   comment.char = "#", 
                   encoding = "UTF-8" , 
                   col.names = paste0("V",seq_len(11)), 
                   fill = TRUE, 
                   stringsAsFactors = FALSE)
  colnames(data) = c("Time", "MD5", "ControllerType", "SentenceNoInStimFile", "Element", "exp_condition", "item", "Sentence", "Question","Answer", "RT")
  
  subject_id <- with(data, { as.integer(as.factor(paste(Time, MD5))) })
  data$item[data$exp_condition == "intro" | data$exp_condition == "practice"] <- 0
  data$item_num <- as.integer(data$item)
  data$subject <- sprintf("S[%d]", subject_id + subj_offset)
  data$item <- sprintf("I[%d]", data$item_num + item_offset)
  
  df_forms <- data %>% subset(ControllerType != "DashedAcceptabilityJudgment" ) %>% gdata::drop.levels()
  data %<>% subset(ControllerType == "DashedAcceptabilityJudgment")
  
  age <- df_forms %>% dplyr::filter(Sentence == "age") %>% 
    dplyr::select(subject, age = Question)
  natturk <- df_forms %>% dplyr::filter(Sentence == "natturk") %>% 
    dplyr::select(subject, natturk = Question) %T>% 
    { .$natturk %<>% recode(male ="nat_turk", female = "nat_non_turk") } 
  forms <- dplyr::left_join(age, natturk, by = "subject")
  
  stopifnot( nrow(data) %% 2 == 0 )
  rows_stim <- data[c(T,F),]
  rows_resp <- data[c(F,T),]
  stopifnot( all(is.na( rows_stim$RT )) )
  
  data <- rows_resp %>% left_join(forms) %>% 
    dplyr::select(-MD5, -Time, -ControllerType, -Sentence, -Element) %>%
    dplyr::rename(ResponseCorrect=Answer, Response=Question) %>%
    dplyr::select(-ResponseCorrect)
  data %<>% group_by(subject) %>% mutate(trial_no = seq(subject))
  data %<>% mutate( late_response = (Response == "NULL"), Response = ifelse(late_response, NA, as.character(Response)) )
  
  responses <- c(yes="İYİ (P'ye basınız)", no="KÖTÜ (Q'ya basınız)")
  data$Response %<>% as.character() %>% enc2native()
  stopifnot( all(data$Response %in% responses | is.na(data$Response) ) )
  
  data$response_yes <- ifelse(grepl("P'ye",data$Response) , T, 
                              ifelse(grepl("Q'ya",data$Response) , F, NA))
  if(verbose){print( with(data, table(Response, response_yes)) )}
  data %<>% dplyr::select(-Response)
  data
}


exclude_bad_subjects <- function(data_to_clean, accuracy_threshold = 0.25, rt_below = 200, rt_upper = 4999, verbose = F) {
  avg_by_subj <- data_to_clean %>%
    group_by(subject, experiment, condition, 
             grammatical, verb_num, attractor_num) %>%
    summarize(avRT = mean(RT), 
              p_yes = mean(response_yes, na.rm = T), 
              N = sum(!is.na(response_yes))  )
  
  avg_by_subj_wide <- avg_by_subj %>% 
    mutate(expcond = paste(experiment, condition, sep="_")) %>% 
    ungroup() %>%
    dplyr::select(-experiment, -condition, -avRT, -N,
                  -grammatical, -verb_num, -attractor_num) %>%
    tidyr::spread(expcond, p_yes) %>% 
    mutate(delta_dc = AgrAttr_d - AgrAttr_c)
  
  bad_subjects <- subset(avg_by_subj_wide, delta_dc <= accuracy_threshold ) %>% .$subject
  data_clean <- data_to_clean %>% subset(!subject %in% bad_subjects)
  
  data_clean %<>% filter(RT < rt_upper & rt_below< RT)
  if("natturk" %in% colnames(data_clean)){
    data_clean %<>% subset(natturk == "nat_turk")
  }
  
  if(verbose){
    print( with(data_clean, table(exp_condition, response_yes)) )
    print( sprintf("number of bad subjects: %f", length(bad_subjects)))
  }
  
  data_clean
  
}

no_null_no_practice <- function(data_to_clean) {
  data_to_clean %<>% subset(exp_condition != "practice") %>% subset(!is.na(response_yes))
}

asi <- function(x) {as.integer(x)}
asf <- function(x) {as.factor(x)}
asc <- function(x) {as.character(x)}


```


# Introduction 

Speakers often rely on additional sources of information when processing sentences, including plausability, frequency, distributional expectations about forms and tasks, as well as the overall composition of an experimental session (e.g., the ratio of fillers to critical items).  Recent work has demonstrated that such task or item-specific factors can substantially modulate reading and judgment behavior [@LauraMalsbug24; @ArehalliWittenberg2021; @HammerlyEtAl2019; @LogacevVasishth2016].  One line of research has used the agreement-attraction phenomenon to probe the heuristics that influence sentence processing.  Agreement attraction refers to cases in which a verb erroneously agrees with a nearby noun rather than the true subject, giving rise to so-called grammaticality illusions in both production and comprehension [@BockMiller:1991; @PearlmutterGarnseyBock:1999].

```{=latex}
\begin{exe}
\ex[*]{\label{og}The key to the cabinets are rusty.} 
\end{exe}
```

Agreement errors in sentences like (\ref{og}) have been treated either as a failure of feature reconcilation or a failure of memory encoding.  The former set of accounts explain these errors as a by-product of how number feature of a phrase is calculated in real-time [@BockMiller:1991; @EberhardEtAl2005; @HammerlyEtAl2019].  For example, @EberhardEtAl2005 argue that depending on conceptual number, morphophonological number marking, or syntactic dependencies within a phrase, speakers assign a probabilistic number value to phrases.  The errors arise when additional plurality features from different sources end up contributing to the final number representation of a phrase.  On the other hand, the latter set of accounts claim that the initial representation is not erroneous, but speakers are sometimes unable to correctly retrieve the controller [@WagersEtAl:2009; @Dillon2013a].  For example, @WagersEtAl:2009 argue that the parser normally check the agreement relation by retrieving the relevant chunk in memory using the retrieval cues provided by the agreement probe.  In sentences like (1), speakers occasionally retrieve the incorrect element due to the fact that neither nouns fully match the relevant cues.

However, both group of accounts generally are underspecified in terms of how meta-linguistic information should be integrated to the inter-sentential dependency mechanisms.  Recently, a growing literature have been testing how different types of additional sources that are independent of the linguistic information affects these errors.  Recent experiments show that even small changes in task expectations can alter attraction patterns. For example, @LauraMalsbug24 found that varying the practice structure and task demands (reading vs. judgment) affected reading times at the verb in sentences as in (\ref{malsburg}).  In a series of high-powered self-paced reading tasks, they found that when participants answered a comprehension question after each trial, reading times at the verb 'admires' did not differ between (\ref{malsburg-singer}) and (\ref{malsburg-singers}).  However, when participants were asked to judge grammaticality instead, they spent more time reading the verb 'admires' in (\ref{malsburg-singers}), suggesting that processing mechanisms can change depending on the expected task.


```{=latex}
\begin{exe}
\ex \label{malsburg}
\begin{xlist}
\ex \label{malsburg-singer} The singer that the actor openly admires apparently received broad international recognition.
\ex \label{malsburg-singers} The singers that the actor openly admires apparently received broad international recognition.
\end{xlist}
\end{exe}
```

A related set of findings came from @HammerlyEtAl2019.  They challenge long-standing assumption that the agreement errors only surfaced in ungrammatical sentences such as (\ref{og}), but not in grammatical sentences as in (\ref{og-g}).  It has been repeatedly shown that a plural noun increased participants' likelihood to erroneously judge ungrammatical sentences as grammatical; however, participants rarely misidentified grammatical sentences as ungrammatical even when there is an attractor.  @HammerlyEtAl2019 showed that similar effect surfaced in grammatical sentences when participants' a priori expectations about the experiment is altered.  They manipulated the instructions and the number of ungrammatical in an experiment so that participants expected to see more ungrammatical sentences than grammatical sentences.  With reduced bias towards grammaticality, they found that the presence of a plural nearby noun affected how speakers completed ungrammatical sentences (\ref{og}) and grammatical sentences (\ref{og-g}) [see @Turk2022 for acceptability]. 

```{=latex}
\begin{exe}
\ex[]{\label{og-g}The key to the cabinets is rusty.}
\end{exe}
```

Another set of meta-linguistic information that comes from form-driven task strategies.  In some languages, surface-form similarity to the agreement controller can exacerbate attraction [BUNCH OF PAPERS] or even drive illusions on its own [CHROMY].  @HartsuikerEtAl2003, for example, used the the accusative marked determiners' form similarity to the nominative marked articles in German, that can be the determiner of an agreement controller, and compared them to distinctively marked dative marked determiners. They showed that participants made agreement errors more often when the preambles contained two NPs that are not marked distinctively (\ref{ger-amb}) compared to cases where the attractor is distinguishable solely using the form (\ref{ger-dist}).  More importantly, this effect only surfaced when the head and the distractors are both nouns with feminine gender, and not masculine or neuter gender, which do not show the surface level similarity in plurals.

```{=latex}
\begin{exe}
\ex \label{ger}
\begin{xlist}
\ex \label{ger-amb}
\gll Die Stellungnahme gegen die Demonstration-en\\
the.F.NOM.SG position against the.F.ACC.PL demonstration-PL\\
\glt `The position against the demonstrations' 
\ex \label{ger-dist}
\gll Die Stellungnahme zu den Demonstration-en\\
the.F.NOM.SG position on the.F.DAT.PL demonstration-PL\\
\glt `the position on the demonstrations' 
\end{xlist}
\end{exe}
```

The most striking evidence comes from work by @Slioussar2018, who showed that surface form can sometimes override abstract features in Russian.  Exploiting the syncretism between singular genitives and nominative plurals, a pattern absent in plural genitives, she found that participants made more production and comprehension errors and showed faster reading times in sentences like (\ref{rus-gen-sg}) than in (\ref{rus-gen-pl}).  This finding is fairly surprising given that a noun that is unambigously singular and only *seems* plural due to form similarity can induce more attraction errors, than grammatically plural nouns.  She argued that, rather than accessing abstract case features, speakers and comprehenders sometimes relied on surface-level cues that were easier to retrieve.

```{=latex}
\begin{exe}
\ex \label{rus}
\begin{xlist}
\ex \label{rus-gen-sg}
\gll Korobka dlya kraski byla/*byli \ldots \\
box.F.SG.NOM for paint.GEN.SG$_{=NOM.PL}$ be.PST.F.SG/*be.PST.F.PL \\
\glt `A box for the paint(s) was/*were \dots'
\ex \label{rus-gen-pl}
\gll Korobka dlya krasok byla/*byli \ldots \\
box.F.SG.NOM for paint.GEN.PL$_{\neq NOM.PL}$ be.PST.F.SG/*be.PST.F.PL \\
\glt `A box for the paint(s) was/*were \dots'
\end{xlist}
\end{exe}
```
Together, these studies converge on the idea that speakers are sensitive not only to the immediate syntactic cues in a sentence, but also to broader distributional regularities that shape how those cues are interpreted.  Some of these regularities reflect long-term experience with the language, such as recurring patterns of form syncretism and probability of being a controller, while others arise within the course of a single experiment, as participants adjust to the statistical composition of the materials, the frequency of ungrammatical items, or the mix of structure types they encounter.  These findings raise the possibility that agreement attraction is not a fixed structural reflex, but rather a dynamic outcome of how the processing system weighs and re-weights cues based on both linguistic and contextual experience.  If so, the strength and even the presence of attraction effects should depend on how strongly surface form and feature structure are correlated in the input, and on what participants learn about those correlations in real time.

Building on these observations, we utilize Turkish as a testing ground to examine how surface-form overlap influences agreement processing and whether exposure to different kinds of distractors modulates attraction. 

- Previous attraction findings in Turkish
- Prior work has reported typical attraction effects with genitive-marked nominal attractors, showing higher acceptance of ungrammatical plural-verb sentences.
- However, no work has directly tested whether verbal plural morphology can induce similar illusions, or how mixing different attractor types within an experiment affects the magnitude of attraction.

Turkish provides an especially informative case because both nominal and verbal plural markers are realized with the same morpheme, –lAr, yet only nominal plurals bear the syntactic features required for agreement. This allows us to ask whether participants rely on surface-form similarity or on abstract feature representations when evaluating agreement.


- Morphological properties
- Turkish marks number on both nouns and verbs using the identical plural morpheme –lAr.
- Only nominal plurals introduce number features that can agree with the verb; verbal –lAr expresses verbal agreement but is not a potential controller.
- Because of this homophony, Turkish allows form-overlap and feature-mismatch to be disentangled experimentally.


In our first experiment, we test whether plural marking on a verbal distractor—which is morphologically identical but syntactically irrelevant—can elicit attraction. In the second experiment, we combine these verbal distractor conditions with standard nominal attractor conditions to assess how their co-occurrence affects participants’ judgments. If attraction effects reflect flexible, context-sensitive processing, the inclusion of verbal distractors should dilute or eliminate the illusion typically observed with nominal attractors.

Together, these experiments extend previous findings on agreement attraction and task sensitivity in two key ways. First, they show that surface-level overlap—even when morphologically identical—does not by itself produce agreement attraction, indicating that participants rely on abstract morphosyntactic features rather than phonological forms. Second, they reveal that participants are not only influenced by the global structure of an experiment (such as the proportion of fillers or grammatical items) but also by the presence of other condition types within the same task. In other words, attraction effects are attenuated when competing, non-attracting conditions are included, suggesting that agreement processing is dynamically tuned to the statistical context of the experiment itself.




## Experimental logic and predictions

- Goal 1: test whether purely form-based overlap (verbal –lAr) elicits attraction.
- Prediction: if attraction is driven by form, verbal plural distractors should yield higher “acceptable” rates for ungrammatical plurals.
- Alternative: if attraction depends on abstract features, no effect of verbal –lAr should appear.

- Goal 2: test whether the co-occurrence of different attractor types modulates attraction.
- Prediction: if participants adapt to the distribution of conditions, adding verbal distractors (which share the plural form but lack agreement features) should attenuate or eliminate the nominal-attractor illusion.
- Summary: These experiments jointly test whether agreement attraction in Turkish reflects shallow form matching or feature-based computation that is sensitive to the statistical context of the task.

# Experiment 1: Testing Form-Driven Processing 

```{r exp1-data-prep}

exp1 <- read_experimental_data("../data/results.txt", subj_offset = 2000, item_offset = 2000) 

exp1 %<>% mutate(exp_condition = case_when(
  exp_condition == "filler" & item_num <= 120 ~ "filler_ung",
  exp_condition == "filler" & item_num >= 121 ~ "filler_g",
  exp_condition == "practice" ~ "practice",
  exp_condition == "condition_b" ~ "condition_b",
  exp_condition == "condition_a" ~ "condition_a",
  exp_condition == "condition_c" ~ "condition_c",
  exp_condition == "condition_d" ~ "condition_d"
))


exp1.conditions <- data.frame(
  exp_condition = c("practice", "condition_a", "condition_b", "condition_c", "condition_d", "filler_ung", "filler_g"),
  experiment =    c("practice", "AgrAttr",     "AgrAttr",     "AgrAttr",     "AgrAttr",     "filler",     "filler"),
  condition =     c("practice", "a",           "b",           "c",           "d",           "filler_ung", "filler_g"),
  grammatical =   c("practice", "ungram",      "gram",        "ungram",      "gram",        "ungram",     "gram"),
  verb_num =      c("practice", "pl",          "sg",          "pl",          "sg",          "sg",         "pl"),
  attractor_num = c("practice", "pl",          "pl",          "sg",          "sg",          'filler',     'filler'),
  match =         c("practice", "mismatch",    "mismatch",    "match",       "match",       'filler',     'filler'),
  stringsAsFactors = T
)

exp1 %<>% left_join(exp1.conditions, by = "exp_condition")

exp1.no.practice <- exp1 %>% subset(exp_condition != "practice")

# accuracy: 0.25
# rt_below: 200
# rt_upper: 4999
exp1.clean <- exclude_bad_subjects(
  exp1,
  accuracy_threshold = 0.25,
  rt_below = 200,
  rt_upper = 4999
)

exp1.clean %<>% no_null_no_practice(.)

stopifnot(exp1.clean %>% subset(is.na(response_yes)) %>% nrow() == 0)

# DIFF DATA =====
exp1.diff <- dplyr::anti_join(exp1, exp1.clean) %>%
  filter(exp_condition != "practice")

exp1.clean$isGram <- ifelse(exp1.clean$grammatical == "ungram", F, T)
exp1.clean$p_acc <- with(exp1.clean, response_yes & isGram)
exp1.clean %<>% mutate(ResponseCorrect = (response_yes == (grammatical == "gram")))

# Merge

exp1.clean %<>% ungroup() %>% 
                      dplyr::select(source=experiment, 
                                    grammatical, 
                                    attractor_num,
                                    match,
                                    age,
                                    # condition,
                                    subject, 
                                    trial_no,
                                    item,
                                    response_yes, 
                                    RT,
                                    ResponseCorrect)
exp1.clean$experiment <- "Experiment 1"
exp1.clean$grammatical %<>% dplyr::recode(gram="grammatical", ungram="ungrammatical")
exp1.clean$attractor_num %<>% dplyr::recode(pl="plural", sg="singular")
exp1.clean$item %<>% as.factor()
exp1.clean$subject %<>% as.character()

```

```{r exp1-avgs}

exp1.avgs <- exp1.clean %>%
  filter(match != "filler") %>%
  group_by(grammatical, attractor_num, match) %>%
  summarise(
    successes = sum(response_yes == 1, na.rm = TRUE),
    N         = sum(!is.na(response_yes)),
    .groups = "drop"
  ) %>%
  mutate(ci_mat = purrr::pmap(
    list(successes, N),
    ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
  )) %>%
  mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
  unnest(ci_mat) %>%    
  mutate(
    p_hat = successes / N,
    lwr   = lwr.ci,
    upr   = upr.ci
  ) %>%
  select(grammatical, attractor_num, match, successes, N, p_hat, lwr, upr)

exp1.avgs.filler <- exp1.clean %>%
  filter(match == "filler") %>%
  group_by(grammatical, attractor_num, match) %>%
  summarise(
    successes = sum(response_yes == 1, na.rm = TRUE),
    N         = sum(!is.na(response_yes)),
    .groups = "drop"
  ) %>%
  mutate(ci_mat = purrr::pmap(
    list(successes, N),
    ~ DescTools::BinomCI(x = ..1, n = ..2, conf.level = 0.95, method = "clopper-pearson")
  )) %>%
  mutate(ci_mat = purrr::map(ci_mat, ~ as_tibble(.))) %>%
  unnest(ci_mat) %>%    
  mutate(
    p_hat = successes / N,
    lwr   = lwr.ci,
    upr   = upr.ci
  ) %>%
  select(grammatical, attractor_num, match, successes, N, p_hat, lwr, upr)


```

```{r exp1-text-inputs}
# I want accuracy, not the response yes
exp1.avgs.filler %<>% 
  mutate(old.lwr = lwr, old.upr = upr) %>% 
  mutate(
  p_hat = if_else(grammatical == "ungrammatical", 1 - p_hat, p_hat),
  lwr = if_else(grammatical == "ungrammatical", 1 - old.upr, old.lwr),
  upr = if_else(grammatical == "ungrammatical", 1 - old.lwr, old.upr))  %>% 
  select(-old.lwr, -old.upr)


exp1.nsubj <- exp1$subject %>% unique() %>% length() 

exp1.nsubj.nontr <- exp1 %>%
  subset(natturk == "nat_non_turk") %>%
  .$subject %>%
  unique() %>%
  length()

exp1.nsubj.threshold <- 2

exp1.deletion <- round(100*((nrow(exp1.no.practice)-nrow(exp1.clean))  / nrow(exp1.no.practice)),2)


exp1.meanage <- mean(asi(exp1.clean$age)) %>% round()
exp1.maxage <- max(asi(exp1.clean$age))
exp1.minage <- min(asi(exp1.clean$age))

# FILLER AVERAGES

exp1.avgs.filler %<>% mutate(text = paste0("M = ", round(p_hat,2), ", CI = [", round(lwr,2) , ",", round(upr,2) ,"]"))

exp1.avgs %<>% mutate(text = paste0("M = ", round(p_hat,2), ", CI = [", round(lwr,2) , ",", round(upr,2) ,"]"))

```


## Participants

We recruited `r exp1.nsubj` undergraduate students to participate in the experiment in exchange for course credit. All participants were native Turkish speakers, with an average age of `r exp1.meanage` (range: `r exp1.minage` – `r exp1.maxage`). The experiment was carried out following the principles of the Declaration of Helsinki and the regulations concerning research ethics at Bogazici University. All participants provided informed consent before their participation and their identities were completely anonymised.

## Materials

We used 40 sets of sentences like (\ref{exp}), in which we manipulated (i) the number of the attractor and (ii) the number agreement on the verb. Both plural markings were marked with the suffix -ler/-lar, while the singular number and singular agreement were marked by its absence. 

```{=latex}
\begin{exe}
\ex \label{exp}
\begin{xlist}
\ex[]{\label{ss}
\gll Tut-tuğ-u aşçı mutfak-ta sürekli zıpla-dı.\\
hire-NMLZ-POSS cook[NOM] kitchen-LOC non.stop jump-PST\\
\glt `The cook they hired$_{sg}$ jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{sp}
\gll Tut-tuğ-u aşçı mutfak-ta sürekli zıpla-dı-lar.\\
hire-NMLZ-POSS cook[NOM] kitchen-LOC non.stop jump-PST-PL\\
\glt `The cook they hired$_{sg}$ jumped$_{pl}$ in the kitchen non-stop.'}
\ex[]{\label{ps}
\gll Tut-tuk-lar-ı aşçı mutfak-ta sürekli zıpla-dı.\\
hire-NMLZ-PL-POSS cook[NOM] kitchen-LOC non.stop jump-PST\\
\glt `The cook they hired$_{pl}$ jumped$_{sg}$ in the kitchen non-stop.'}
\ex[*]{\label{pp}
\gll Tut-tuk-lar-ı aşçı mutfak-ta sürekli zıpla-dı-lar.\\
hire-NMLZ-PL-POSS cook[NOM] kitchen-LOC non.stop jump-PST-PL\\
\glt `The cook they hired$_{pl}$ jumped$_{pl}$ in the kitchen non-stop.'}
\end{xlist}
\end{exe}
```

All sentences were adapted by previous studies in Turkish agreement attraction [@LagoEtAl2019;@TurkLogacev2020]. Sentences started with a complex subject NP like 'tuttukları aşçı' 'the cook they hired,' in which the nominalized relative clause functioned as the attractor, and the head noun were bare. Because the plural marking on nominals is not optional and the head noun was singular, absent of -lar, in all conditions, sentences with plural verb agreement were ungrammatical. To inhibit participants from forming a task-related strategy in which they deemed the sentence ungrammatical upon seeing a plural verb, half of our fillers included plural grammatical verbs, while the other half included singular ungrammatical verbs.

## Procedures

The experiment was run online, using the web-based platform Ibex Farm [@Drummond2013]. Each experimental session took approximately 25 minutes to complete. Participants provided demographic information and gave informed consent to participate in the experiment. They then proceeded to read the instructions and were given nine practice trials before the experiment began.

Each trial began with a blank screen for 600 ms, followed by a word-by-word RSVP presentation of the sentence in the center of the screen, followed by a prompt to indicate their acceptability judgment. Sentences were presented word-by-word in the center of the screen in 30 pt font size, at a rate of 400 ms per word. Participants saw a blank screen for 100 ms between each word, and to see the next item, they needed to press the space key. Participants were asked to press the key P to indicate that a sentence is acceptable and Q to indicate that the sentence is unacceptable. They were instructed to provide judgments as quickly as possible. During the practice, but not during the experiment, a warning message in red font appeared if they did not respond within 5,000 ms.

Participants saw 40 experimental and 40 filler sentences. Experimental sentences were distributed among four different lists according to a Latin-square design. Every participant saw one version of the experiment with a specific list and one item per condition.


## Analysis and Results

```{r exp1-plot}

exp1.gram.label <- c(
    grammatical = "Grammatical\n(Singular Verb)",
    ungrammatical = "Ungrammatical\n(Plural Verb)"
)

# responses 

exp1.avgs %>%
    ggplot(aes(grammatical, p_hat, 
            linetype = attractor_num, 
            group = attractor_num)) + 
    geom_point() + geom_line() + 
    geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.1) + 
    theme(strip.background = element_rect(fill="white")) +
    xlab("Grammaticality") + 
    ylab("Percentage 'acceptable'") + 
    scale_y_continuous(labels=scales::percent) + 
    scale_linetype_discrete(name = "Attractor Number", 
                            labels = c("Plural", "Singular")) + 
    scale_x_discrete(labels = exp1.gram.label) +
    theme_minimal(base_family = "Times") + 
    theme(legend.position = 'bottom') 

```


```{r exp1-models, eval=FALSE}
options(mc.cores = parallel::detectCores())
theme_set(theme_bw(base_family = "Times"))


exp1.dfModel <- exp1.clean %>% subset(match != "filler")


exp1.dfModel %<>%
  mutate(
    grammatical     = factor(grammatical,
                         levels = c("grammatical","ungrammatical"),
                         labels = c("Grammatical","Ungrammatical")),
    attractor_num   = factor(attractor_num,  # or attractor_num if that’s your column
                         levels = c("singular","plural"),
                         labels = c("Singular","Plural"))
  )

# Sum-code ±0.5 and give readable column names
C2 <- contr.sum(2) / 2

Cg <- C2; colnames(Cg) <- "Ungram_minus_Gram"      # β > 0 ⇒ Ungram > Gram (in log-odds of YES)
Ca <- C2; colnames(Ca) <- "Plural_minus_Singular"  # β > 0 ⇒ Plural > Singular (log-odds of YES)

contrasts(exp1.dfModel$grammatical) <- Cg
contrasts(exp1.dfModel$attractor_num)   <- Ca

make_priors <- function(inter_mean = 0.4, inter_sd = 0.25,
                             exp_rate = 2, lkj_eta = 2) {
  c(
    set_prior("normal(0.85, 0.7)", class = "Intercept"),
    set_prior("normal(-1.0, 0.5)", class = "b",
              coef = "grammaticalUngram_minus_Gram"),
    set_prior("normal(0.30, 0.40)", class = "b",
              coef = "attractor_numPlural_minus_Singular"),
    set_prior(sprintf("normal(%g, %g)", inter_mean, inter_sd),
              class = "b",
              coef = "grammaticalUngram_minus_Gram:attractor_numPlural_minus_Singular"),
    set_prior(sprintf("exponential(%g)", exp_rate), class = "sd"),
    set_prior(sprintf("lkj(%g)", lkj_eta), class = "cor")
  )
}


# Default: mean 0.4, sd 0.25 (the “interaction” model)
#exp2.priors_interaction_exp <- make_exp2_priors()

# Near-zero interaction model
#exp2.priors_no_interaction_exp <- make_exp2_priors(inter_mean = 0, inter_sd = 0.10)

# Strong positive interaction (e.g. mean 0.8)
#exp2.priors_strong_interaction <- make_exp2_priors(inter_mean = 0.8, inter_sd = 0.25)

m.exp1.int <- brm(
  response_yes ~ grammatical * attractor_num +
    (1 + grammatical * attractor_num | subject) +
    (1 + grammatical * attractor_num | item),
  data   = exp1.dfModel,
  family = bernoulli(link = "logit"),
  prior  = make_priors(inter_mean = 0, inter_sd = 0.10),
  sample_prior = "yes",           
  chains = 4, iter = 4000, warmup = 1000, seed = 1
)


m.exp1.no.int <- brm(
  response_yes ~ grammatical * attractor_num +
    (1 + grammatical * attractor_num | subject) +
    (1 + grammatical * attractor_num | item),
  data   = exp1.dfModel,
  family = bernoulli(link = "logit"),
  prior  = make_priors(),
  sample_prior = "yes",           
  chains = 4, iter = 4000, warmup = 1000, seed = 1
)


```

- Goal: determine if surface plural forms (verbal -lAr) elicit illusionary agreement.
- Participants: 80 Turkish speakers (Boğaziçi undergraduates).
- Design: 2 × 2 (Grammaticality × Attractor Number).
- Materials: relative-clause verbs as attractors; same surface morphology as nominal plurals.
- Procedure: speeded acceptability judgments, 1500 ms deadline.
- Analysis: Bayesian probit GLM (brms); random intercepts/slopes by subject/item.
- Results:
  - High filler accuracy (> .9).
  - No difference in ungrammatical sentences between plural vs singular attractors.
  - Posterior coefficients near 0; 95 % CIs within ROPE.
- Discussion:
  - No evidence for form-driven guessing.
  - Participants rely on abstract number features, not phonological similarity.




# Experiment 2: Testing Within-Experiment Statistical Sensitivity 

```{r exp2-data-prep}

```

```{r exp2-avgs}

```

```{r exp2-text-inputs}

```

## Participants

We recruited 118 undergraduate students to participate in the experiment in exchange for course credit. All participants were native Turkish speakers, with an average age of 20 (range: 18 – 32). The experiment was carried out following the principles of the Declaration of Helsinki and the regulations concerning research ethics at Bogazici University. All participants provided informed consent before their participation and their identities were completely anonymised.

## Materials

The same materials were used with Exp1. 
We added items from TurkLogacev2024 as an additional condition.

## Procedures

The same procedure with Experiment 1 was used.


## Analysis and Results

```{r exp2-models}

```

- Goal: test whether attraction changes when both attractor types occur in one experiment.
- Participants: 95 Turkish speakers.
- Design: 2 × 2 × 2 (Grammaticality × Attractor Number × Attractor Type [nominal vs verbal]).
- Procedure & analysis: same as Experiment 1.
- Results:
  - Attraction replicated for nominal attractors (Δ ≈ 0.07).
  - Verbal attractors again showed null effect.
  - Global decline in yes-responses relative to earlier studies → participants became more conservative.
- Discussion:
  - Exposure to verbal conditions reduced attraction magnitude overall.
  - Indicates participants adapt to statistical properties of the task.
  - Aligns with learning-based cue-weighting accounts (Haskell et al. 2010).

# General Discussion 
- Synthesis:
  - No evidence for surface-form matching; effects are feature-based.
  - Attraction magnitude changes with condition distribution → adaptive tuning.
- Interpretation:
  - Supports an adaptive parser sensitive to within-experiment statistics.
  - Challenges “shallow” or “good-enough” accounts that attribute attraction to phonological overlap.
- Broader implication:
  - Agreement processing is flexible and probabilistic; illusions arise from learned cue validity.
- Limitations:
  - Syntactic depth asymmetry (verbal attractors more embedded).
  - Need future designs equating structure (e.g., embedded-object attractors).
- Conclusion:
  - Turkish attraction effects arise from abstract feature retrieval not surface level shallow form-matching.  
  - The evaluation of abstract features are modulated by distributional learning within the experiment. 


<!-- # Abbreviations {.unnumbered} -->

<!-- \printglossaries -->

```{r message=FALSE, warning=FALSE, echo=FALSE, output=FALSE}
# system("makeglossaries paper")
```

# References {.unnumbered}

\newcommand{\doi}[1]{\href{http://dx.doi.org/#1}{http://dx.doi.org/#1}}
\begingroup
\raggedright
\singlespacing
::: {#refs}
:::
\endgroup